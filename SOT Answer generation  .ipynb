{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb645680-41ca-42c1-b8e9-971b0d65d71e",
   "metadata": {},
   "source": [
    "## Sketch of thought"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "781253f2-9837-4346-9ff2-c50b69426aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sketch_of_thought import SoT\n",
    "\n",
    "# Initialize SoT\n",
    "sot = SoT()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80889b3d-56f9-4547-9359-4210e07bd18b",
   "metadata": {},
   "source": [
    "## AS sample we have take either of these 3 questions , you can write you own \n",
    "\n",
    "### AS Cheerayu Chowhan who should I ask for job reffral based on other profile data ? \n",
    "### How Many Profiles are there which come from SRM and NMIMS universities and have expertise in machine leasrning and data analytics ? \n",
    "### Summerize the Cheerayu Chowhan's work experience at Impact guru based on available data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb58e986-aa04-4198-a77c-a5d5ebee32a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classified Paradigm: conceptual_chaining\n"
     ]
    }
   ],
   "source": [
    "# Classify a question to determine the best reasoning paradigm\n",
    "question = \"Summerize the Cheerayu Chowhan's work experience at Impact guru based on available data.\"\n",
    "paradigm = sot.classify_question(question)\n",
    "print(\"Classified Paradigm:\", paradigm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcb20fe-f3d1-4b27-bb59-3501893cb116",
   "metadata": {},
   "source": [
    "## Conceptual_chaining system Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c05c939-44aa-446a-80e4-1246cea38225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the custom conceptual chaining system prompt tailored for HR and LinkedIn profile data\n",
    "conceptual_chaining_prompt = \"\"\"\n",
    "## **Role & Objective**  \n",
    "You are a **reasoning expert** specializing in **structured concept linking** for HR-driven knowledge retrieval. Your goal is to decompose complex queries into investigative sub-questions by logically connecting essential entities such as people, institutions, skills, roles, and projects. The objective is to trace meaningful paths in LinkedIn profile data—including work experience, education, posts, interactions, articles, volunteer work, projects, languages, and courses—to generate targeted questions for graph-based retrieval.\n",
    "\n",
    "This approach follows a **Conceptual Chaining Logic (CCL)** method where:\n",
    "- You extract key entities (e.g., job titles, universities, skills).\n",
    "- You decompose the main query into a series of investigative sub-questions.\n",
    "- Each sub-question is designed to guide retrieval from the knowledge graph, focusing on multi-hop relationships and professional networks.\n",
    "\n",
    "This method is most effective for:\n",
    "- Professional networking analysis (identifying referral sources, mentorship, or skill overlaps).\n",
    "- Tracing career trajectories (education → experience → skills → roles).\n",
    "- Retrieving context-aware data from LinkedIn profiles.\n",
    "\n",
    "## **How to Apply This Reasoning Method**  \n",
    "1. **Extract Key Entities & Relations** → Identify critical people, institutions, skills, and roles.  \n",
    "2. **Decompose into Investigative Sub-Questions** → Generate precise sub-queries targeting different aspects of the main question.  \n",
    "3. **Link Questions Sequentially** → Use logical dependencies (indicated by arrows `→`) to build a progressive chain of inquiry.  \n",
    "4. **Frame as Investigative Questions** → Return probing sub-questions that enable refined graph retrieval, rather than direct answers.\n",
    "\n",
    "## **Rules & Directives**  \n",
    "1. **Structured Investigative Reasoning:**  \n",
    "   - Each sub-question must logically connect to the main query.  \n",
    "   - Use arrows (`→`) to indicate dependencies between questions.\n",
    "\n",
    "2. **Generate Investigative Questions, Not Direct Answers:**  \n",
    "   - Do not restate or answer the main query directly.  \n",
    "   - Instead, output a series of investigative sub-questions.\n",
    "\n",
    "3. **Maintain Logical Flow:**  \n",
    "   - Ensure each sub-question builds on previous ones to progressively narrow the search space.\n",
    "\n",
    "4. **Output Format:**  \n",
    "   Use the exact format below:\n",
    "\n",
    "   <investigate> \n",
    "   - Q1 → Investigative Question 1 \n",
    "   - Q2 → Investigative Question 2 \n",
    "   - Q3 → Investigative Question 3 \n",
    "   </investigate> \\boxed{[Final retrieval question]} ``` \n",
    "   The final retrieval question should be boxed and represent the refined overall inquiry for graph retrieval.\n",
    "\n",
    "## **Example for Reference:**\n",
    "    Main Query: “As Eric, who should I ask for a job referral?”\n",
    "    Investigation might include:\n",
    "\n",
    "    <investigate>\n",
    "    - Q1 → Who in Eric's network shares the same university (NMIMS)?\n",
    "    - Q2 → Who has worked at the same company or in similar roles?\n",
    "    - Q3 → Which connections have demonstrated active engagement (posts, interactions)?\n",
    "    </investigate>\n",
    "    \\boxed{Which candidate in Eric’s network is best suited to provide a job referral?}\n",
    "    \"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c910d4-4b38-4ab4-b8ec-ee716111d9f6",
   "metadata": {},
   "source": [
    "# Chunked Symbolism prompt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ef0908a-044c-457b-a58b-c2082ccfa99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the custom Chunked Symbolism system prompt tailored for HR and quantitative LinkedIn profile data\n",
    "chunked_symbolism_prompt = \"\"\"\n",
    "## **Role & Objective**  \n",
    "You are a **reasoning expert** specializing in **Chunked Symbolism for HR analytics**. Your goal is to decompose quantitative HR queries into precise, investigative sub-questions by representing key metrics through equations, variables, and step-by-step arithmetic. The objective is to analyze LinkedIn profile data—including work experience metrics, performance improvements, automation impact figures, and project outcomes—to generate targeted, numerical investigative questions.\n",
    "\n",
    "This approach follows a **Chunked Symbolism Logic (CSL)** method where:  \n",
    "- You extract relevant numerical values and define variables (e.g., efficiency percentages, reduction in manual effort, years of experience).  \n",
    "- You represent relationships using **explicit mathematical formulas** and structured calculations.  \n",
    "- You decompose the main query into a series of investigative sub-questions that refine the quantitative analysis, enabling precise retrieval from the knowledge graph.\n",
    "\n",
    "This method is most effective for:  \n",
    "- **Quantitative HR analysis** (calculating performance metrics, efficiency improvements, and growth rates).  \n",
    "- **Symbolic reasoning** (formula derivations based on numerical data).  \n",
    "- **Technical evaluation of career transitions** (measuring impact of automation, role transitions, and process optimizations).\n",
    "\n",
    "## **How to Apply This Reasoning Method**  \n",
    "1. **Identify Key Metrics & Variables** → Extract numerical values (e.g., percentages, counts, durations) from the query.  \n",
    "2. **Define Equations** → Represent relationships using clear mathematical expressions.  \n",
    "3. **Decompose into Investigative Sub-Questions** → Generate specific sub-queries that target aspects like change over time, performance improvement, or efficiency metrics.  \n",
    "4. **Frame as Investigative Questions** → Instead of providing a direct answer, output probing sub-questions that narrow down the search for numerical data in LinkedIn profiles.\n",
    "\n",
    "## **Rules & Directives**  \n",
    "1. **Use Equations & Variables:**  \n",
    "   - Define variables clearly before computation.  \n",
    "   - Always use explicit equations to represent reasoning steps.\n",
    "\n",
    "2. **Generate Investigative Questions, Not Direct Answers:**  \n",
    "   - Do not restate or answer the main query directly.  \n",
    "   - Instead, output a series of quantitative, investigative sub-questions.\n",
    "\n",
    "3. **Maintain Logical, Step-by-Step Arithmetic:**  \n",
    "   - Break down the problem into small, structured steps with one computation per line.\n",
    "\n",
    "4. **Output Format:**  \n",
    "   Use the exact format below:\n",
    "    <think> \n",
    "    - Q1 → Investigative Question 1 (e.g., Identify the baseline efficiency metric from past roles) \n",
    "    - Q2 → Investigative Question 2 (e.g., Calculate the percentage reduction in manual effort post-automation) \n",
    "    - Q3 → Investigative Question 3 (e.g., Determine the average improvement in performance metrics) \n",
    "    </think> \\boxed{[Final refined quantitative retrieval question]} ``` \n",
    "    The final boxed question should summarize the overall investigative inquiry for numerical data retrieval.\n",
    "\n",
    "    Example for Reference\n",
    "    Main Query: “What is the improvement in work efficiency for employees who transitioned to automation roles?”\n",
    "    A possible decomposition might be:\n",
    "\n",
    "    <think>\n",
    "    - Q1 → What is the baseline efficiency (in %) before automation in past roles?\n",
    "    - Q2 → What is the recorded efficiency after transitioning to automation roles?\n",
    "    - Q3 → What is the percentage change in efficiency?\n",
    "    </think>\n",
    "    \\boxed{What is the calculated efficiency improvement for employees after automation?}\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226a9288-c2df-4ff9-aaf5-ff97d408d74e",
   "metadata": {},
   "source": [
    "# Expert lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf123cc8-6734-43bd-846c-9a24f6133f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the updated custom Expert Lexicon system prompt for HR and LinkedIn profile data\n",
    "\n",
    "expert_lexicon_prompt = \"\"\"\n",
    "## **Role & Objective**  \n",
    "You are a reasoning expert specializing in **Expert Lexicons** for HR analytics and LinkedIn profile data. Your goal is to decompose complex queries into targeted, investigative sub-questions that reveal key insights about professional profiles. You will generate clear, context-driven investigative questions that guide data retrieval and analysis without relying on shorthand notation.\n",
    "\n",
    "This method is particularly effective for:\n",
    "- Professional networking analysis\n",
    "- Career trajectory investigations\n",
    "- Context-aware HR data retrieval\n",
    "\n",
    "--- \n",
    "\n",
    "## **How to Apply Expert Lexicons**  \n",
    "### **Step-by-Step Guide**\n",
    "1. **Extract Key Entities & Metrics** → Identify essential HR elements such as job titles, skills, institutions, performance metrics, and network connections.\n",
    "2. **Decompose into Investigative Sub-Questions** → Break down the main query into clear, targeted questions that progressively narrow the search scope.\n",
    "3. **Maintain Context and Clarity** → Ensure each question is self-contained, easily understandable, and focused on retrieving actionable insights.\n",
    "4. **Link Questions Sequentially** → Organize the questions to build upon each other and guide further inquiry.\n",
    "\n",
    "--- \n",
    "\n",
    "## **Rules & Directives**  \n",
    "1. **Generate Investigative Questions, Not Direct Answers**  \n",
    "   - Output a series of investigative sub-questions rather than providing direct answers.\n",
    "2. **Ensure Clarity and Context**  \n",
    "   - Each question must clearly relate to key HR data points in LinkedIn profiles.\n",
    "3. **Maintain Logical Flow**  \n",
    "   - Arrange questions in a sequential order that gradually refines the inquiry.\n",
    "4. **Output Format (Investigative Questions as Output)**  \n",
    "   Use the exact structured format:\n",
    "\n",
    "   <think> \n",
    "   - Q1 → [Investigative Question 1] \n",
    "   - Q2 → [Investigative Question 2] \n",
    "   - Q3 → [Investigative Question 3] \n",
    "   </think> \\boxed{[Final refined investigative question for retrieval]} ``` \n",
    "   - The final answer must be boxed. \n",
    "   - Use full sentences and clear language in your questions. \"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5fa3ff-8347-4348-ac91-f261ea32ce1b",
   "metadata": {},
   "source": [
    "# Using Sketch of thought to enhance the querry based on the innate logic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da9b6629-3259-43ad-987e-16427ab8fd30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<investigate>\n",
      "- Q1 → What specific roles did Cheerayu Chowhan hold at Impact Guru?\n",
      "- Q2 → What were the dates of employment for each role at Impact Guru?\n",
      "- Q3 → What were the key responsibilities and accomplishments listed for each role at Impact Guru?\n",
      "- Q4 → Are there any publicly available performance reviews or internal documents related to Cheerayu Chowhan's work at Impact Guru? (Note: This may not be publicly accessible data)\n",
      "</investigate>\n",
      "\boxed{[Summarize Cheerayu Chowhan's work experience at Impact Guru based on the extracted roles, dates, responsibilities, and accomplishments.]}\n",
      "\n",
      "Boxed Queries List: [\"Summarize Cheerayu Chowhan's work experience at Impact Guru based on the extracted roles, dates, responsibilities, and accomplishments.\"]\n",
      "Combined List: ['- Q1 → What specific roles did Cheerayu Chowhan hold at Impact Guru?', '- Q2 → What were the dates of employment for each role at Impact Guru?', '- Q3 → What were the key responsibilities and accomplishments listed for each role at Impact Guru?', \"- Q4 → Are there any publicly available performance reviews or internal documents related to Cheerayu Chowhan's work at Impact Guru? (Note: This may not be publicly accessible data)\", \"Summarize Cheerayu Chowhan's work experience at Impact Guru based on the extracted roles, dates, responsibilities, and accomplishments.\"]\n",
      "Response saved in file: conceptual_chaining_Summerize_the_Cheerayu_Chowhans_work_experience_at_Impact_guru_based_on_available_data.txt\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "import re\n",
    "\n",
    "# Select the appropriate system prompt based on the paradigm\n",
    "if paradigm == \"conceptual_chaining\":\n",
    "    system_prompt = conceptual_chaining_prompt\n",
    "elif paradigm == \"chunked_symbolism\":\n",
    "    system_prompt = chunked_symbolism_prompt\n",
    "elif paradigm == \"expert_lexicon\":\n",
    "    system_prompt = expert_lexicon_prompt\n",
    "else:\n",
    "    raise ValueError(\"Invalid paradigm selected.\")\n",
    "\n",
    "# Create a Gemini client using your API key\n",
    "client = genai.Client(api_key=\"AIzaSyCjbGRnG3XdvIeUTKnwZ1HgS0sSYGg-t5E\")\n",
    "\n",
    "# Generate content using the selected system prompt and question.\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-1.5-flash\",\n",
    "    config=types.GenerateContentConfig(\n",
    "        system_instruction=system_prompt,\n",
    "        max_output_tokens=5000,\n",
    "        temperature=0.1\n",
    "    ),\n",
    "    contents=[question]\n",
    ")\n",
    "\n",
    "# Retrieve the text from the response\n",
    "response_text = response.text\n",
    "print(response_text)\n",
    "\n",
    "# Create a file name by combining a sanitized version of the question with the paradigm used.\n",
    "short_question = re.sub(r'[^a-zA-Z0-9 ]', '', question)  # Remove punctuation\n",
    "short_question = re.sub(r'\\s+', '_', short_question.strip())  # Replace spaces with underscores\n",
    "file_name = f\"{paradigm}_{short_question}.txt\"\n",
    "\n",
    "# Save the response (along with system prompt and query) in the file using UTF-8 encoding.\n",
    "with open(file_name, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"System Prompt Used:\\n\")\n",
    "    f.write(system_prompt + \"\\n\\n\")\n",
    "    f.write(\"Query:\\n\")\n",
    "    f.write(question + \"\\n\\n\")\n",
    "    f.write(\"Response:\\n\")\n",
    "    f.write(response_text + \"\\n\\n\")\n",
    "    \n",
    "    # Extract the enhanced (boxed) query: search for text enclosed in \"{[ ... ]}\" after \"</investigate>\"\n",
    "    boxed_query_list = re.findall(r'</investigate>.*?\\{\\[(.*?)\\]\\}', response_text, re.DOTALL)\n",
    "    \n",
    "    # Cleanup the extracted query list if necessary\n",
    "    boxed_query_list = [q.strip() for q in boxed_query_list]\n",
    "    \n",
    "    f.write(\"Boxed Query:\\n\")\n",
    "    f.write(\"\\n\".join(boxed_query_list))\n",
    "    \n",
    "    print(\"Boxed Queries List:\", boxed_query_list)\n",
    "\n",
    "    # Extract the investigate section (all text between <investigate> and </investigate>)\n",
    "    investigate_section = re.search(r'<investigate>(.*?)</investigate>', response_text, re.DOTALL)\n",
    "    investigate_questions_list = []\n",
    "    if investigate_section:\n",
    "        # Split the section into individual lines and filter out empty lines\n",
    "        investigate_questions_list = [line.strip() for line in investigate_section.group(1).splitlines() if line.strip()]\n",
    "    \n",
    "    # Extract the boxed query as before\n",
    "    boxed_query_list = re.findall(r'</investigate>.*?\\{\\[(.*?)\\]\\}', response_text, re.DOTALL)\n",
    "    boxed_query_list = [q.strip() for q in boxed_query_list]\n",
    "    \n",
    "    # Combine the two lists into a new variable\n",
    "    combined_list = investigate_questions_list + boxed_query_list\n",
    "    \n",
    "    print(\"Combined List:\", combined_list)\n",
    "\n",
    "\n",
    "print(f\"Response saved in file: {file_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ecb324c-9176-4397-a3c7-027689a6765b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boxed Queries List: [\"Summarize Cheerayu Chowhan's work experience at Impact Guru based on the extracted roles, dates, responsibilities, and accomplishments.\"]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Boxed Queries List:\", boxed_query_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0b795d8-1f56-478a-9870-c2dbcd5a4cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Summarize Cheerayu Chowhan's work experience at Impact Guru based on the extracted roles, dates, responsibilities, and accomplishments.\"]\n"
     ]
    }
   ],
   "source": [
    "sample_queries = boxed_query_list\n",
    "print(sample_queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6548c2b-3161-4098-a000-eb54855ddc87",
   "metadata": {},
   "source": [
    "# Passing Enhanced query to query decomposition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7cd48a83-616d-47f4-a8a5-6f51fdcc56e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Processing Query 1 ====\n",
      "\n",
      "Generated Rewriting Prompt:\n",
      " You need to segment the given query then extract the potential knowledge graph structures.\n",
      "\n",
      "Notes)\n",
      "1). Use the original description in the query with enough context. Do not use unspecific words like 'in', 'is', 'for', 'of', 'have', 'go to', etc.\n",
      "2). For nodes or relations that are unknown, use the keyword 'UNKNOWN' with a unique ID (e.g., 'UNKNOWN artist 1', 'UNKNOWN relation 1').\n",
      "3). For negations (e.g., 'not', 'wasn't', 'didn't'), mark the negated nodes as 'UNKNOWN' (e.g., 'A does not live in B' becomes ('A', 'live in', 'UNKNOWN location 1')).\n",
      "4). For numeric values, preserve the value in double quotes (e.g., '\"156\"') and use scientific notation if needed (e.g., '\"5.2E06\"').\n",
      "5). Return the segmented query and extracted graph strictly in the format:\n",
      "    {\n",
      "        \"divided\": [\n",
      "            \"segment 1\",\n",
      "            ...\n",
      "        ],\n",
      "        \"graph\": [\n",
      "            ('head', 'relation', 'tail'),\n",
      "            ...\n",
      "        ]\n",
      "    }\n",
      "6). Do not include any extra explanations.\n",
      "\n",
      "Examples:\n",
      "\n",
      "1. query: 'Elon Musk is the CEO of SpaceX.'\n",
      "{\n",
      "    \"divided\": ['Elon Musk is the CEO', 'of SpaceX'],\n",
      "    \"graph\": [('Elon Musk', 'is CEO of', 'SpaceX')]\n",
      "}\n",
      "\n",
      "2. query: 'The Louvre Museum is located in Paris.'\n",
      "{\n",
      "    \"divided\": ['The Louvre Museum is located', 'in Paris'],\n",
      "    \"graph\": [('Louvre Museum', 'located in', 'Paris')]\n",
      "}\n",
      "\n",
      "3. query: 'J.K. Rowling wrote the Harry Potter series.'\n",
      "{\n",
      "    \"divided\": ['J.K. Rowling wrote', 'the Harry Potter series'],\n",
      "    \"graph\": [('J.K. Rowling', 'wrote', 'Harry Potter series')]\n",
      "}\n",
      "\n",
      "4. query: 'Apple Inc. designs iPhones and iPads.'\n",
      "{\n",
      "    \"divided\": ['Apple Inc. designs', 'iPhones and iPads'],\n",
      "    \"graph\": [('Apple Inc.', 'designs', 'iPhones'), ('Apple Inc.', 'designs', 'iPads')]\n",
      "}\n",
      "\n",
      "5. query: 'Amazon is known for its fast delivery and e-commerce platform.'\n",
      "{\n",
      "    \"divided\": ['Amazon is known for', 'fast delivery', 'and e-commerce platform'],\n",
      "    \"graph\": [('Amazon', 'is known for', 'fast delivery'), ('Amazon', 'is known for', 'e-commerce platform')]\n",
      "}\n",
      "\n",
      "6. query: 'The Great Wall of China is a historic fortification.'\n",
      "{\n",
      "    \"divided\": ['The Great Wall of China is', 'a historic fortification'],\n",
      "    \"graph\": [('Great Wall of China', 'is', 'historic fortification')]\n",
      "}\n",
      "\n",
      "7. query: 'Toyota manufactures reliable automobiles.'\n",
      "{\n",
      "    \"divided\": ['Toyota manufactures', 'reliable automobiles'],\n",
      "    \"graph\": [('Toyota', 'manufactures', 'reliable automobiles')]\n",
      "}\n",
      "\n",
      "8. query: 'Shakespeare wrote many timeless plays including Hamlet.'\n",
      "{\n",
      "    \"divided\": ['Shakespeare wrote', 'many timeless plays', 'including Hamlet'],\n",
      "    \"graph\": [('Shakespeare', 'wrote', 'Hamlet')]\n",
      "}\n",
      "\n",
      "9. query: 'Google is a leader in internet search technology.'\n",
      "{\n",
      "    \"divided\": ['Google is a leader', 'in internet search technology'],\n",
      "    \"graph\": [('Google', 'is leader in', 'internet search technology')]\n",
      "}\n",
      "\n",
      "10. query: 'Tesla produces electric vehicles and sustainable energy products.'\n",
      "{\n",
      "    \"divided\": ['Tesla produces', 'electric vehicles', 'and sustainable energy products'],\n",
      "    \"graph\": [('Tesla', 'produces', 'electric vehicles'), ('Tesla', 'produces', 'sustainable energy products')]\n",
      "}\n",
      "\n",
      "11. query: 'The Eiffel Tower is an iconic landmark in Paris.'\n",
      "{\n",
      "    \"divided\": ['The Eiffel Tower is an iconic landmark', 'in Paris'],\n",
      "    \"graph\": [('Eiffel Tower', 'is landmark in', 'Paris')]\n",
      "}\n",
      "\n",
      "12. query: 'Netflix offers streaming services and original content.'\n",
      "{\n",
      "    \"divided\": ['Netflix offers', 'streaming services', 'and original content'],\n",
      "    \"graph\": [('Netflix', 'offers', 'streaming services'), ('Netflix', 'offers', 'original content')]\n",
      "}\n",
      "\n",
      "Your task)\n",
      "**Read and follow the instructions and examples step by step**\n",
      "query: 'Summarize Cheerayu Chowhan's work experience at Impact Guru based on the extracted roles, dates, responsibilities, and accomplishments.'\n",
      "\n",
      "Calling Gemini API...\n",
      "\n",
      "Gemini API Response:\n",
      " ```json\n",
      "{\n",
      "  \"divided\": [\"Summarize Cheerayu Chowhan's work experience\", \"at Impact Guru\", \"based on the extracted roles, dates, responsibilities, and accomplishments\"],\n",
      "  \"graph\": [(\"Cheerayu Chowhan\", \"work experience at\", \"Impact Guru\"), (\"UNKNOWN role 1\", \"UNKNOWN relation 1\", \"UNKNOWN responsibility 1\"), (\"UNKNOWN role 1\", \"UNKNOWN relation 2\", \"UNKNOWN accomplishment 1\"), (\"UNKNOWN role 2\", \"UNKNOWN relation 3\", \"UNKNOWN responsibility 2\"), (\"UNKNOWN role 2\", \"UNKNOWN relation 4\", \"UNKNOWN accomplishment 2\"), (\"UNKNOWN date 1\", \"UNKNOWN relation 5\", \"UNKNOWN role 1\"), (\"UNKNOWN date 2\", \"UNKNOWN relation 6\", \"UNKNOWN role 2\")]\n",
      "}\n",
      "```\n",
      "\n",
      "Extracted Query Graph:\n",
      "[('Cheerayu Chowhan', 'work experience at', 'Impact Guru'), ('UNKNOWN role 1', 'UNKNOWN relation 1', 'UNKNOWN responsibility 1'), ('UNKNOWN role 1', 'UNKNOWN relation 2', 'UNKNOWN accomplishment 1'), ('UNKNOWN role 2', 'UNKNOWN relation 3', 'UNKNOWN responsibility 2'), ('UNKNOWN role 2', 'UNKNOWN relation 4', 'UNKNOWN accomplishment 2'), ('UNKNOWN date 1', 'UNKNOWN relation 5', 'UNKNOWN role 1'), ('UNKNOWN date 2', 'UNKNOWN relation 6', 'UNKNOWN role 2')]\n",
      "Saved image for Query 1 as: kg_visualization_query_1.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All query graphs have been saved in all_extracted_query_graphs.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ast\n",
    "import json\n",
    "import re\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import google.generativeai as genai\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# --- Configure Gemini API ---\n",
    "# Either set GEMINI_API_KEY env variable or pass your key directly.\n",
    "genai.configure(api_key=os.environ.get(\"GEMINI_API_KEY\", \"AIzaSyCjbGRnG3XdvIeUTKnwZ1HgS0sSYGg-t5E\"))\n",
    "model = genai.GenerativeModel('gemini-1.5-flash')\n",
    "\n",
    "# --- Provided query rewriting prompt examples (updated for our project) ---\n",
    "examples = [\n",
    "    {\n",
    "        \"query\": \"Elon Musk is the CEO of SpaceX.\",\n",
    "        \"divided\": [\n",
    "            \"Elon Musk is the CEO\",\n",
    "            \"of SpaceX\"\n",
    "        ],\n",
    "        \"graph\": [\n",
    "            (\"Elon Musk\", \"is CEO of\", \"SpaceX\")\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"The Louvre Museum is located in Paris.\",\n",
    "        \"divided\": [\n",
    "            \"The Louvre Museum is located\",\n",
    "            \"in Paris\"\n",
    "        ],\n",
    "        \"graph\": [\n",
    "            (\"Louvre Museum\", \"located in\", \"Paris\")\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"J.K. Rowling wrote the Harry Potter series.\",\n",
    "        \"divided\": [\n",
    "            \"J.K. Rowling wrote\",\n",
    "            \"the Harry Potter series\"\n",
    "        ],\n",
    "        \"graph\": [\n",
    "            (\"J.K. Rowling\", \"wrote\", \"Harry Potter series\")\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Apple Inc. designs iPhones and iPads.\",\n",
    "        \"divided\": [\n",
    "            \"Apple Inc. designs\",\n",
    "            \"iPhones and iPads\"\n",
    "        ],\n",
    "        \"graph\": [\n",
    "            (\"Apple Inc.\", \"designs\", \"iPhones\"),\n",
    "            (\"Apple Inc.\", \"designs\", \"iPads\")\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Amazon is known for its fast delivery and e-commerce platform.\",\n",
    "        \"divided\": [\n",
    "            \"Amazon is known for\",\n",
    "            \"fast delivery\",\n",
    "            \"and e-commerce platform\"\n",
    "        ],\n",
    "        \"graph\": [\n",
    "            (\"Amazon\", \"is known for\", \"fast delivery\"),\n",
    "            (\"Amazon\", \"is known for\", \"e-commerce platform\")\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"The Great Wall of China is a historic fortification.\",\n",
    "        \"divided\": [\n",
    "            \"The Great Wall of China is\",\n",
    "            \"a historic fortification\"\n",
    "        ],\n",
    "        \"graph\": [\n",
    "            (\"Great Wall of China\", \"is\", \"historic fortification\")\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Toyota manufactures reliable automobiles.\",\n",
    "        \"divided\": [\n",
    "            \"Toyota manufactures\",\n",
    "            \"reliable automobiles\"\n",
    "        ],\n",
    "        \"graph\": [\n",
    "            (\"Toyota\", \"manufactures\", \"reliable automobiles\")\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Shakespeare wrote many timeless plays including Hamlet.\",\n",
    "        \"divided\": [\n",
    "            \"Shakespeare wrote\",\n",
    "            \"many timeless plays\",\n",
    "            \"including Hamlet\"\n",
    "        ],\n",
    "        \"graph\": [\n",
    "            (\"Shakespeare\", \"wrote\", \"Hamlet\")\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Google is a leader in internet search technology.\",\n",
    "        \"divided\": [\n",
    "            \"Google is a leader\",\n",
    "            \"in internet search technology\"\n",
    "        ],\n",
    "        \"graph\": [\n",
    "            (\"Google\", \"is leader in\", \"internet search technology\")\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Tesla produces electric vehicles and sustainable energy products.\",\n",
    "        \"divided\": [\n",
    "            \"Tesla produces\",\n",
    "            \"electric vehicles\",\n",
    "            \"and sustainable energy products\"\n",
    "        ],\n",
    "        \"graph\": [\n",
    "            (\"Tesla\", \"produces\", \"electric vehicles\"),\n",
    "            (\"Tesla\", \"produces\", \"sustainable energy products\")\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"The Eiffel Tower is an iconic landmark in Paris.\",\n",
    "        \"divided\": [\n",
    "            \"The Eiffel Tower is an iconic landmark\",\n",
    "            \"in Paris\"\n",
    "        ],\n",
    "        \"graph\": [\n",
    "            (\"Eiffel Tower\", \"is landmark in\", \"Paris\")\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Netflix offers streaming services and original content.\",\n",
    "        \"divided\": [\n",
    "            \"Netflix offers\",\n",
    "            \"streaming services\",\n",
    "            \"and original content\"\n",
    "        ],\n",
    "        \"graph\": [\n",
    "            (\"Netflix\", \"offers\", \"streaming services\"),\n",
    "            (\"Netflix\", \"offers\", \"original content\")\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "def get(query, shot=12):\n",
    "    prompt = \"\"\"You need to segment the given query then extract the potential knowledge graph structures.\n",
    "\n",
    "Notes)\n",
    "1). Use the original description in the query with enough context. Do not use unspecific words like 'in', 'is', 'for', 'of', 'have', 'go to', etc.\n",
    "2). For nodes or relations that are unknown, use the keyword 'UNKNOWN' with a unique ID (e.g., 'UNKNOWN artist 1', 'UNKNOWN relation 1').\n",
    "3). For negations (e.g., 'not', 'wasn't', 'didn't'), mark the negated nodes as 'UNKNOWN' (e.g., 'A does not live in B' becomes ('A', 'live in', 'UNKNOWN location 1')).\n",
    "4). For numeric values, preserve the value in double quotes (e.g., '\"156\"') and use scientific notation if needed (e.g., '\"5.2E06\"').\n",
    "5). Return the segmented query and extracted graph strictly in the format:\n",
    "    {\n",
    "        \"divided\": [\n",
    "            \"segment 1\",\n",
    "            ...\n",
    "        ],\n",
    "        \"graph\": [\n",
    "            ('head', 'relation', 'tail'),\n",
    "            ...\n",
    "        ]\n",
    "    }\n",
    "6). Do not include any extra explanations.\n",
    "\n",
    "Examples:\n",
    "\"\"\"\n",
    "    for i in range(min(shot, len(examples))):\n",
    "        prompt += f\"\"\"\n",
    "{i+1}. query: '{examples[i]['query']}'\n",
    "{{\n",
    "    \"divided\": {examples[i]['divided']},\n",
    "    \"graph\": {examples[i]['graph']}\n",
    "}}\n",
    "\"\"\"\n",
    "    return prompt + f\"\"\"\n",
    "Your task)\n",
    "**Read and follow the instructions and examples step by step**\n",
    "query: '{query}'\n",
    "\"\"\"\n",
    "\n",
    "# Dictionary to store extracted query graphs for all queries\n",
    "all_query_graphs = {}\n",
    "\n",
    "# Process each query\n",
    "for idx, sample_query in enumerate(sample_queries):\n",
    "    print(f\"\\n==== Processing Query {idx+1} ====\")\n",
    "    \n",
    "    rewriting_prompt = get(sample_query, shot=12)\n",
    "    print(\"\\nGenerated Rewriting Prompt:\\n\", rewriting_prompt)\n",
    "    \n",
    "    print(\"Calling Gemini API...\")\n",
    "    response = model.generate_content(rewriting_prompt)\n",
    "    response_text = response.text.strip() if response and hasattr(response, \"text\") else \"\"\n",
    "    print(\"\\nGemini API Response:\\n\", response_text)\n",
    "    \n",
    "    # --- Extract graph structure from the Gemini response ---\n",
    "    try:\n",
    "        def extract_graph(llm_output):\n",
    "            try:\n",
    "                matched = re.search(r'\\{.*\\}', llm_output, re.DOTALL)\n",
    "                if not matched:\n",
    "                    raise Exception(\"No graph structure found in LLM output.\")\n",
    "                decoded = ast.literal_eval(matched.group(0))\n",
    "                return decoded.get(\"graph\", [])\n",
    "            except Exception as e:\n",
    "                raise Exception(\"Failed to extract graph: \" + str(e))\n",
    "        query_graph = extract_graph(response_text)\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting graph for query {idx+1}: {e}\")\n",
    "        query_graph = []\n",
    "    \n",
    "    print(\"\\nExtracted Query Graph:\")\n",
    "    print(query_graph)\n",
    "    \n",
    "    # Save the extracted graph into our dictionary\n",
    "    all_query_graphs[sample_query] = query_graph\n",
    "    \n",
    "    # --- Build a Knowledge Graph from the Query Graph using NetworkX ---\n",
    "    G = nx.DiGraph()\n",
    "    for triple in query_graph:\n",
    "        head, relation, tail = triple\n",
    "        G.add_node(head, label=head)\n",
    "        G.add_node(tail, label=tail)\n",
    "        G.add_edge(head, tail, label=relation, title=f\"{head} {relation} {tail}\")\n",
    "    \n",
    "    # --- Visualize the Graph as a static image using Matplotlib ---\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    pos = nx.spring_layout(G)\n",
    "    nx.draw(G, pos, with_labels=True, node_color=\"#AED6F1\", edge_color=\"gray\", node_size=1500, font_size=10)\n",
    "    edge_labels = nx.get_edge_attributes(G, 'label')\n",
    "    nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_color='red')\n",
    "    plt.title(f\"Extracted Query KG for Query {idx+1}\")\n",
    "    plt.axis('off')\n",
    "    output_path = f\"kg_visualization_query_{idx+1}.png\"\n",
    "    plt.savefig(output_path, format=\"PNG\")\n",
    "    plt.close()  # Close the figure to avoid display overlap\n",
    "    print(f\"Saved image for Query {idx+1} as: {output_path}\")\n",
    "    image_path = output_path\n",
    "    display(Image(output_path))\n",
    "\n",
    "# --- Save all extracted query graphs into a file ---\n",
    "output_graphs_file = \"all_extracted_query_graphs.json\"\n",
    "with open(output_graphs_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(all_query_graphs, f, indent=4)\n",
    "print(f\"\\nAll query graphs have been saved in {output_graphs_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e3bf34-0954-4fb0-bda7-76af9b196100",
   "metadata": {},
   "source": [
    "# After query decomposition we embed question parts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4a77dc3-c5b5-4bf5-96bb-b3bad28c1dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: Summarize Cheerayu Chowhan's work experience at Impact Guru based on the extracted roles, dates, responsibilities, and accomplishments.\n",
      "Unique Query Nodes: ['UNKNOWN role 1', 'Impact Guru', 'UNKNOWN responsibility 2', 'UNKNOWN role 2', 'UNKNOWN accomplishment 2', 'UNKNOWN accomplishment 1', 'UNKNOWN date 1', 'UNKNOWN responsibility 1', 'UNKNOWN date 2', 'Cheerayu Chowhan']\n",
      "Unique Query Relations: ['UNKNOWN relation 5', 'UNKNOWN relation 3', 'UNKNOWN relation 4', 'UNKNOWN relation 1', 'UNKNOWN relation 2', 'work experience at', 'UNKNOWN relation 6']\n",
      "Node Embeddings Shape: (10, 384)\n",
      "Relation Embeddings Shape: (7, 384)\n",
      "\n",
      "All query embeddings have been saved in query_embeddings.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import ast\n",
    "import re\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# --- File path for all extracted query graphs ---\n",
    "query_graphs_file = \"all_extracted_query_graphs.json\"\n",
    "\n",
    "# Load the extracted query graphs\n",
    "with open(query_graphs_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    all_query_graphs = json.load(f)\n",
    "\n",
    "# Initialize the embedding model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "embedding_dim = 384\n",
    "\n",
    "# Dictionary to store embeddings for each query\n",
    "all_query_embeddings = {}\n",
    "\n",
    "# Process each query graph\n",
    "for query, graph in all_query_graphs.items():\n",
    "    unique_nodes = set()\n",
    "    unique_relations = set()\n",
    "    \n",
    "    # Extract unique nodes and relations from the graph (list of triples)\n",
    "    for triple in graph:\n",
    "        if isinstance(triple, (list, tuple)) and len(triple) == 3:\n",
    "            head, relation, tail = triple\n",
    "            unique_nodes.add(head)\n",
    "            unique_nodes.add(tail)\n",
    "            unique_relations.add(relation)\n",
    "        else:\n",
    "            print(f\"Skipping invalid triple: {triple}\")\n",
    "    \n",
    "    unique_nodes = list(unique_nodes)\n",
    "    unique_relations = list(unique_relations)\n",
    "    \n",
    "    print(f\"\\nQuery: {query}\")\n",
    "    print(\"Unique Query Nodes:\", unique_nodes)\n",
    "    print(\"Unique Query Relations:\", unique_relations)\n",
    "    \n",
    "    # --- Batch encode nodes and relations ---\n",
    "    node_embeddings = model.encode(unique_nodes, batch_size=8)\n",
    "    relation_embeddings = model.encode(unique_relations, batch_size=8)\n",
    "    \n",
    "    node_embeddings = np.array(node_embeddings)  # shape: (num_nodes, 384)\n",
    "    relation_embeddings = np.array(relation_embeddings)  # shape: (num_relations, 384)\n",
    "    \n",
    "    print(\"Node Embeddings Shape:\", node_embeddings.shape)\n",
    "    print(\"Relation Embeddings Shape:\", relation_embeddings.shape)\n",
    "    \n",
    "    # Save embeddings in a JSON-compatible format (convert numpy arrays to lists)\n",
    "    all_query_embeddings[query] = {\n",
    "        \"unique_nodes\": unique_nodes,\n",
    "        \"node_embeddings\": node_embeddings.tolist(),\n",
    "        \"unique_relations\": unique_relations,\n",
    "        \"relation_embeddings\": relation_embeddings.tolist()\n",
    "    }\n",
    "\n",
    "# Save all query embeddings into a file for later use\n",
    "output_embeddings_file = \"query_embeddings.json\"\n",
    "with open(output_embeddings_file, \"w\", encoding=\"utf-8\") as out_f:\n",
    "    json.dump(all_query_embeddings, out_f, indent=4)\n",
    "\n",
    "print(f\"\\nAll query embeddings have been saved in {output_embeddings_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6803ac3-ab25-490c-b130-2239deb78a81",
   "metadata": {},
   "source": [
    "# using the question embedding we match with our KG "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4eed08-10c3-41e3-9944-672d9470341a",
   "metadata": {},
   "source": [
    "## you need to include files from indexer folder \n",
    "\n",
    "### kg_entities_word_embeddings.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a90bf84-b709-4540-a7b2-587b8f2f6aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query matching results saved to: C:\\Users\\cheer\\rv_v1.3\\SOT\\SoT\\query_matches.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# --- Settings ---\n",
    "query_embeddings_file = \"query_embeddings.json\"            # Previously saved query embeddings file\n",
    "kg_file = \"kg_entities_word_embeddings.json\"                # KG word-level embeddings file\n",
    "output_file = \"query_matches.json\"                           # Output file to store matches\n",
    "model_name = \"all-MiniLM-L6-v2\"\n",
    "SIMILARITY_THRESHOLD = 0.8\n",
    "\n",
    "# --- Helper Functions ---\n",
    "def load_json(filepath):\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def cosine_similarity(a, b):\n",
    "    # Avoid division by zero with a small epsilon.\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b) + 1e-8)\n",
    "\n",
    "def compute_word_embedding(word, model):\n",
    "    \"\"\"Compute the embedding for a given word using the provided model.\"\"\"\n",
    "    return model.encode(word)\n",
    "\n",
    "# --- Load Data ---\n",
    "query_data = load_json(query_embeddings_file)\n",
    "kg_data = load_json(kg_file)\n",
    "\n",
    "# Initialize the MiniLM model.\n",
    "model = SentenceTransformer(model_name)\n",
    "\n",
    "# --- Prepare Results Container ---\n",
    "# We will record matches separately for nodes and relations.\n",
    "results = {}\n",
    "\n",
    "# --- Process Each Query ---\n",
    "for query, data in query_data.items():\n",
    "    matches = {\"nodes\": [], \"relations\": []}\n",
    "    \n",
    "    # --- Search through query unique nodes ---\n",
    "    for node_text in data.get(\"unique_nodes\", []):\n",
    "        # Split the query node text into individual words (using simple whitespace split)\n",
    "        for qword in node_text.split():\n",
    "            q_emb = compute_word_embedding(qword, model)\n",
    "            # Search in KG nodes\n",
    "            for kg_node_id, kg_node in kg_data.get(\"nodes\", {}).items():\n",
    "                # For each word stored in this KG node\n",
    "                for word_info in kg_node.get(\"words\", []):\n",
    "                    kg_word = word_info.get(\"word\", \"\")\n",
    "                    kg_emb = np.array(word_info.get(\"embedding\"))\n",
    "                    sim = cosine_similarity(q_emb, kg_emb)\n",
    "                    if sim >= SIMILARITY_THRESHOLD:\n",
    "                        entry = {\n",
    "                            \"kg_node_id\": kg_node_id,\n",
    "                            \"original_text\": kg_node.get(\"original_text\", \"\"),\n",
    "                            \"chunk_ids\": kg_node.get(\"chunk_ids\", []),\n",
    "                            \"matched_word\": kg_word,\n",
    "                            \"query_word\": qword,\n",
    "                            \"similarity\": sim\n",
    "                        }\n",
    "                        # Avoid duplicates.\n",
    "                        if not any((e[\"kg_node_id\"] == kg_node_id and e[\"matched_word\"] == kg_word)\n",
    "                                   for e in matches[\"nodes\"]):\n",
    "                            matches[\"nodes\"].append(entry)\n",
    "                        # Once we have a match for this query word in a node, no need to check more words for that node.\n",
    "                        break\n",
    "\n",
    "    # --- Search through query unique relations ---\n",
    "    for rel_text in data.get(\"unique_relations\", []):\n",
    "        for qword in rel_text.split():\n",
    "            q_emb = compute_word_embedding(qword, model)\n",
    "            # First, search in KG nodes (since relations might also be embedded there)\n",
    "            for kg_node_id, kg_node in kg_data.get(\"nodes\", {}).items():\n",
    "                for word_info in kg_node.get(\"words\", []):\n",
    "                    kg_word = word_info.get(\"word\", \"\")\n",
    "                    kg_emb = np.array(word_info.get(\"embedding\"))\n",
    "                    sim = cosine_similarity(q_emb, kg_emb)\n",
    "                    if sim >= SIMILARITY_THRESHOLD:\n",
    "                        entry = {\n",
    "                            \"kg_node_id\": kg_node_id,\n",
    "                            \"original_text\": kg_node.get(\"original_text\", \"\"),\n",
    "                            \"chunk_ids\": kg_node.get(\"chunk_ids\", []),\n",
    "                            \"matched_word\": kg_word,\n",
    "                            \"query_word\": qword,\n",
    "                            \"similarity\": sim\n",
    "                        }\n",
    "                        if not any((e.get(\"kg_node_id\") == kg_node_id and e[\"matched_word\"] == kg_word)\n",
    "                                   for e in matches[\"relations\"]):\n",
    "                            matches[\"relations\"].append(entry)\n",
    "                        break\n",
    "            # Then, search in KG edges if available.\n",
    "            for kg_edge_id, kg_edge in kg_data.get(\"edges\", {}).items():\n",
    "                # Here we assume the edge structure is similar (with an \"original_text\", \"chunk_ids\", and \"words\")\n",
    "                for word_info in kg_edge.get(\"words\", []):\n",
    "                    kg_word = word_info.get(\"word\", \"\")\n",
    "                    kg_emb = np.array(word_info.get(\"embedding\"))\n",
    "                    sim = cosine_similarity(q_emb, kg_emb)\n",
    "                    if sim >= SIMILARITY_THRESHOLD:\n",
    "                        entry = {\n",
    "                            \"kg_edge_id\": kg_edge_id,\n",
    "                            \"original_text\": kg_edge.get(\"original_text\", \"\"),\n",
    "                            \"chunk_ids\": kg_edge.get(\"chunk_ids\", []),\n",
    "                            \"matched_word\": kg_word,\n",
    "                            \"query_word\": qword,\n",
    "                            \"similarity\": sim\n",
    "                        }\n",
    "                        if not any((e.get(\"kg_edge_id\") == kg_edge_id and e[\"matched_word\"] == kg_word)\n",
    "                                   for e in matches[\"relations\"]):\n",
    "                            matches[\"relations\"].append(entry)\n",
    "                        break\n",
    "\n",
    "    results[query] = matches\n",
    "\n",
    "# --- Save the Results ---\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(\"Query matching results saved to:\", os.path.realpath(output_file))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24264ce8-4cb0-42a1-8be0-919a981d955b",
   "metadata": {},
   "source": [
    "# Fetching the chunk ids which will be used in for providing addtional orginal sorce as context "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d48835-6794-4785-a887-9a94648d8c89",
   "metadata": {},
   "source": [
    "## include the file chunk_word_embeddings.json  from indexer folder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "889de65b-14ca-47d5-81a2-cfd534144c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highlighted chunk IDs saved to: C:\\Users\\cheer\\rv_v1.3\\SOT\\SoT\\highlighted_chunk_ids.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# --- Settings ---\n",
    "query_embeddings_file = \"query_embeddings.json\"      # File with query embeddings (unique nodes/relations)\n",
    "chunk_word_embeddings_file = \"chunk_word_embeddings.json\"  # File with chunk word embeddings (structure: {\"data\": [ ... ]})\n",
    "output_file = \"highlighted_chunk_ids.json\"            # Output file\n",
    "model_name = \"all-MiniLM-L6-v2\"\n",
    "SIMILARITY_THRESHOLD = 0.8\n",
    "\n",
    "# --- Helper Functions ---\n",
    "def load_json(filepath):\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def cosine_similarity(a, b):\n",
    "    # Add a small epsilon to avoid division by zero.\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b) + 1e-8)\n",
    "\n",
    "def compute_word_embedding(word, model):\n",
    "    \"\"\"Compute embedding for a given word using the provided model.\"\"\"\n",
    "    return model.encode(word)\n",
    "\n",
    "# --- Load Data ---\n",
    "query_data = load_json(query_embeddings_file)\n",
    "chunk_data = load_json(chunk_word_embeddings_file)  # expecting a dict with key \"data\" that is a list of chunks\n",
    "\n",
    "# Initialize the MiniLM model.\n",
    "model = SentenceTransformer(model_name)\n",
    "\n",
    "# --- Process Each Query ---\n",
    "# This dictionary will store for each query the list of matching chunk IDs.\n",
    "query_matches = {}\n",
    "\n",
    "for query, data in query_data.items():\n",
    "    matching_chunk_ids = set()\n",
    "    \n",
    "    # Process both unique nodes and unique relations from the query.\n",
    "    texts_to_search = []\n",
    "    texts_to_search.extend(data.get(\"unique_nodes\", []))\n",
    "    texts_to_search.extend(data.get(\"unique_relations\", []))\n",
    "    \n",
    "    # For each text (node or relation), split it into words.\n",
    "    for text in texts_to_search:\n",
    "        for qword in text.split():\n",
    "            q_emb = compute_word_embedding(qword, model)\n",
    "            \n",
    "            # Now search through each chunk.\n",
    "            for chunk in chunk_data.get(\"data\", []):\n",
    "                # Get the list of words for the chunk\n",
    "                words_info = chunk.get(\"payload\", {}).get(\"words\", [])\n",
    "                for word_info in words_info:\n",
    "                    kg_emb = np.array(word_info.get(\"embedding\"))\n",
    "                    sim = cosine_similarity(q_emb, kg_emb)\n",
    "                    if sim >= SIMILARITY_THRESHOLD:\n",
    "                        # Record this chunk id.\n",
    "                        matching_chunk_ids.add(chunk.get(\"id\"))\n",
    "                        # Once one word from the chunk matches, we can break out of its loop.\n",
    "                        break\n",
    "    # Save the unique chunk IDs for this query.\n",
    "    query_matches[query] = list(matching_chunk_ids)\n",
    "\n",
    "# --- Save the Results ---\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(query_matches, f, indent=2)\n",
    "\n",
    "print(\"Highlighted chunk IDs saved to:\", os.path.realpath(output_file))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686dc8dd-c338-43d5-8ff3-36a19fa8ff67",
   "metadata": {},
   "source": [
    "# mapping addtional nodes and edges part of highlighted chunk ids "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88096636-9eb0-41d8-bce0-1bea5ef78b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching nodes and edges saved to: C:\\Users\\cheer\\rv_v1.3\\SOT\\SoT\\matching_nodes_edges.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# --- File Paths ---\n",
    "highlighted_chunks_file = \"highlighted_chunk_ids.json\"  # Mapping: query -> list of chunk IDs\n",
    "kg_file = \"kg_entities_word_embeddings.json\"            # KG file containing \"nodes\" and \"edges\"\n",
    "output_file = \"matching_nodes_edges.json\"               # Output file to save matching records\n",
    "\n",
    "def load_json(filepath):\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "# --- Load Data ---\n",
    "highlighted_data = load_json(highlighted_chunks_file)\n",
    "kg_data = load_json(kg_file)\n",
    "\n",
    "# The KG file is assumed to have two top-level keys: \"nodes\" and \"edges\"\n",
    "kg_nodes = kg_data.get(\"nodes\", {})\n",
    "kg_edges = kg_data.get(\"edges\", {})\n",
    "\n",
    "results = {}\n",
    "\n",
    "for query, chunk_ids in highlighted_data.items():\n",
    "    # Create a unique set of chunk IDs for the current query.\n",
    "    unique_chunk_ids = set(chunk_ids)\n",
    "    \n",
    "    # Initialize lists to hold matched nodes and edges.\n",
    "    matched_nodes = []\n",
    "    matched_edges = []\n",
    "    \n",
    "    # Process nodes: iterate over each node record in KG.\n",
    "    for node_id, node_record in kg_nodes.items():\n",
    "        node_chunk_ids = set(node_record.get(\"chunk_ids\", []))\n",
    "        # If there is any intersection, add the node record.\n",
    "        if unique_chunk_ids & node_chunk_ids:\n",
    "            matched_nodes.append({\n",
    "                \"node_id\": node_id,\n",
    "                \"original_text\": node_record.get(\"original_text\", \"\"),\n",
    "                \"chunk_ids\": list(node_chunk_ids),\n",
    "                \"payload\": node_record  # full node info (optional)\n",
    "            })\n",
    "    \n",
    "    # Process edges: iterate over each edge record.\n",
    "    for edge_id, edge_record in kg_edges.items():\n",
    "        raw_chunk_ids = edge_record.get(\"chunk_ids\", [])\n",
    "        if isinstance(raw_chunk_ids, list):\n",
    "            edge_chunk_ids = set(raw_chunk_ids)\n",
    "            if unique_chunk_ids & edge_chunk_ids:\n",
    "                matched_edges.append({\n",
    "                    \"edge_id\": edge_id,\n",
    "                    \"original_text\": edge_record.get(\"original_text\", \"\"),\n",
    "                    \"chunk_ids\": list(edge_chunk_ids),\n",
    "                    \"payload\": edge_record\n",
    "                })\n",
    "        elif isinstance(raw_chunk_ids, str):\n",
    "            # Directly check if the string is in the highlighted chunk ids.\n",
    "            if raw_chunk_ids in unique_chunk_ids:\n",
    "                matched_edges.append({\n",
    "                    \"edge_id\": edge_id,\n",
    "                    \"original_text\": edge_record.get(\"original_text\", \"\"),\n",
    "                    \"chunk_ids\": [raw_chunk_ids],\n",
    "                    \"payload\": edge_record\n",
    "                })\n",
    "    \n",
    "    results[query] = {\n",
    "        \"nodes\": matched_nodes,\n",
    "        \"edges\": matched_edges\n",
    "    }\n",
    "\n",
    "# --- Save the Results ---\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(\"Matching nodes and edges saved to:\", os.path.realpath(output_file))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404a0484-db61-4066-98be-4befef191f74",
   "metadata": {},
   "source": [
    "# Deduplicating nodes and edges in our selection list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5633d7a5-aa8c-40ce-88c8-3aece30d8c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique aggregated nodes and edges saved to: C:\\Users\\cheer\\rv_v1.3\\SOT\\SoT\\unique_aggregated_nodes_edges.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# --- File Paths ---\n",
    "query_matches_file = \"query_matches.json\"               # File with query matches (from word-level matching)\n",
    "matching_nodes_edges_file = \"matching_nodes_edges.json\"   # File with nodes/edges from chunk search\n",
    "output_file = \"unique_aggregated_nodes_edges.json\"        # Output file for unique aggregated nodes/edges\n",
    "\n",
    "def load_json(filepath):\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "# --- Load Data ---\n",
    "qm = load_json(query_matches_file)\n",
    "mne = load_json(matching_nodes_edges_file)\n",
    "\n",
    "# Merge using the union of query keys from both files.\n",
    "all_queries = set(qm.keys()) | set(mne.keys())\n",
    "aggregated_results = {}\n",
    "\n",
    "for query in all_queries:\n",
    "    unique_nodes = {}\n",
    "    unique_edges = {}\n",
    "\n",
    "    # Helper: Return a unique key from a record (node or edge)\n",
    "    def get_unique_key(record, default_key):\n",
    "        return record.get(\"kg_node_id\") or record.get(\"node_id\") or \\\n",
    "               record.get(\"kg_edge_id\") or record.get(\"edge_id\") or default_key\n",
    "\n",
    "    # Process nodes from query_matches file (if available)\n",
    "    if query in qm and \"nodes\" in qm[query]:\n",
    "        for record in qm[query][\"nodes\"]:\n",
    "            key = get_unique_key(record, \"unknown\")\n",
    "            # Use a set to hold chunk IDs\n",
    "            if key in unique_nodes:\n",
    "                unique_nodes[key][\"chunk_ids\"].update(record.get(\"chunk_ids\", []))\n",
    "            else:\n",
    "                unique_nodes[key] = {\n",
    "                    \"unique_id\": key,\n",
    "                    \"original_text\": record.get(\"original_text\", \"\"),\n",
    "                    \"chunk_ids\": set(record.get(\"chunk_ids\", []))\n",
    "                }\n",
    "    \n",
    "    # Process nodes from matching_nodes_edges file (if available)\n",
    "    if query in mne and \"nodes\" in mne[query]:\n",
    "        for record in mne[query][\"nodes\"]:\n",
    "            key = get_unique_key(record, \"unknown\")\n",
    "            if key in unique_nodes:\n",
    "                unique_nodes[key][\"chunk_ids\"].update(record.get(\"chunk_ids\", []))\n",
    "            else:\n",
    "                unique_nodes[key] = {\n",
    "                    \"unique_id\": key,\n",
    "                    \"original_text\": record.get(\"original_text\", \"\"),\n",
    "                    \"chunk_ids\": set(record.get(\"chunk_ids\", []))\n",
    "                }\n",
    "    \n",
    "    # Process edges from query_matches file (if available)\n",
    "    if query in qm and \"edges\" in qm[query]:\n",
    "        for record in qm[query][\"edges\"]:\n",
    "            key = get_unique_key(record, \"unknown\")\n",
    "            if key in unique_edges:\n",
    "                unique_edges[key][\"chunk_ids\"].update(record.get(\"chunk_ids\", []))\n",
    "            else:\n",
    "                unique_edges[key] = {\n",
    "                    \"unique_id\": key,\n",
    "                    \"original_text\": record.get(\"original_text\", \"\"),\n",
    "                    \"chunk_ids\": set(record.get(\"chunk_ids\", []))\n",
    "                }\n",
    "    \n",
    "    # Process edges from matching_nodes_edges file (if available)\n",
    "    if query in mne and \"edges\" in mne[query]:\n",
    "        for record in mne[query][\"edges\"]:\n",
    "            key = get_unique_key(record, \"unknown\")\n",
    "            if key in unique_edges:\n",
    "                unique_edges[key][\"chunk_ids\"].update(record.get(\"chunk_ids\", []))\n",
    "            else:\n",
    "                unique_edges[key] = {\n",
    "                    \"unique_id\": key,\n",
    "                    \"original_text\": record.get(\"original_text\", \"\"),\n",
    "                    \"chunk_ids\": set(record.get(\"chunk_ids\", []))\n",
    "                }\n",
    "    \n",
    "    # Convert the chunk_ids sets to lists for JSON serialization.\n",
    "    aggregated_nodes = []\n",
    "    for node in unique_nodes.values():\n",
    "        node[\"chunk_ids\"] = list(node[\"chunk_ids\"])\n",
    "        aggregated_nodes.append(node)\n",
    "    \n",
    "    aggregated_edges = []\n",
    "    for edge in unique_edges.values():\n",
    "        edge[\"chunk_ids\"] = list(edge[\"chunk_ids\"])\n",
    "        aggregated_edges.append(edge)\n",
    "    \n",
    "    aggregated_results[query] = {\n",
    "        \"nodes\": aggregated_nodes,\n",
    "        \"edges\": aggregated_edges\n",
    "    }\n",
    "\n",
    "# --- Save the Aggregated Output ---\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(aggregated_results, f, indent=2)\n",
    "\n",
    "print(\"Unique aggregated nodes and edges saved to:\", os.path.realpath(output_file))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3c01e4-0e16-49c4-942d-6814b60ec0b7",
   "metadata": {},
   "source": [
    "# Query visualisation for actovated nodes ( alled to traverse in the graph) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5293cb56-b306-4fb7-8f16-43ce2885e560",
   "metadata": {},
   "source": [
    "# you need to include \n",
    "\n",
    "### entity_db.json \n",
    "### relation_db.json\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25c0443d-ef59-497f-8422-e0d8fea6018a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualization for query:\n",
      "  Summarize Cheerayu Chowhan's work experience at Impact Guru based on the extracted roles, dates, responsibilities, and accomplishments.\n",
      "Saved to: C:\\Users\\cheer\\rv_v1.3\\SOT\\SoT\\query_visualizations\\Summarize_Cheerayu_Chowhans_work_experience_at_Impact_Guru_based_on_the_extracted_roles_dates_responsibilities_and_accomplishments.html\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import networkx as nx\n",
    "from pyvis.network import Network\n",
    "import webbrowser\n",
    "import re\n",
    "\n",
    "def load_db(db_file):\n",
    "    \"\"\"Load records from a NanoVectorDB JSON file.\"\"\"\n",
    "    with open(db_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    if isinstance(data, dict) and \"data\" in data:\n",
    "        return data[\"data\"]\n",
    "    elif isinstance(data, list):\n",
    "        return data\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "def normalize_entity(ent):\n",
    "    \"\"\"Normalize an entity string to use as an ID.\"\"\"\n",
    "    return ent.strip().lower().replace(\" \", \"_\")\n",
    "\n",
    "# --- File paths for your saved JSON databases ---\n",
    "entity_db_file = \"entity_db.json\"\n",
    "relation_db_file = \"relation_db.json\"\n",
    "aggregated_file = \"unique_aggregated_nodes_edges.json\"  # Aggregated activated nodes/edges\n",
    "output_dir = \"query_visualizations\"  # Directory to save per-query visualizations\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# --- Load data from the entity and relation JSON files ---\n",
    "entity_records = load_db(entity_db_file)\n",
    "relation_records = load_db(relation_db_file)\n",
    "\n",
    "# --- Build a dictionary of nodes (entities) with full metadata ---\n",
    "nodes = {}\n",
    "for rec in entity_records:\n",
    "    node_id = rec.get(\"id\") or rec.get(\"__id__\")\n",
    "    if not node_id:\n",
    "        continue\n",
    "    rec_meta = rec.copy()\n",
    "    rec_meta[\"label\"] = rec.get(\"payload\", {}).get(\"text\", node_id)\n",
    "    nodes[node_id] = rec_meta\n",
    "\n",
    "# Ensure every entity mentioned in relations exists.\n",
    "for rec in relation_records:\n",
    "    payload = rec.get(\"payload\", {})\n",
    "    ent1 = payload.get(\"entity1\", \"\")\n",
    "    ent2 = payload.get(\"entity2\", \"\")\n",
    "    norm1 = normalize_entity(ent1)\n",
    "    norm2 = normalize_entity(ent2)\n",
    "    if norm1 and norm1 not in nodes:\n",
    "        nodes[norm1] = {\"label\": ent1, \"payload\": {\"text\": ent1}}\n",
    "    if norm2 and norm2 not in nodes:\n",
    "        nodes[norm2] = {\"label\": ent2, \"payload\": {\"text\": ent2}}\n",
    "\n",
    "# --- Build a NetworkX graph using these nodes and relation records as edges ---\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# Add entity nodes to the graph\n",
    "for eid, meta in nodes.items():\n",
    "    G.add_node(eid, **meta)\n",
    "\n",
    "# Add edges based on relation records.\n",
    "for rec in relation_records:\n",
    "    payload = rec.get(\"payload\", {})\n",
    "    ent1 = payload.get(\"entity1\", \"\")\n",
    "    ent2 = payload.get(\"entity2\", \"\")\n",
    "    rel_text = payload.get(\"relation\", \"\")\n",
    "    norm1 = normalize_entity(ent1)\n",
    "    norm2 = normalize_entity(ent2)\n",
    "    if norm1 and norm2:\n",
    "        edge_meta = rec.copy()\n",
    "        edge_meta[\"label\"] = rel_text\n",
    "        G.add_edge(norm1, norm2, **edge_meta)\n",
    "\n",
    "# --- Load Aggregated Activated Nodes/Edges ---\n",
    "with open(aggregated_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    aggregated = json.load(f)\n",
    "\n",
    "# --- For each query, filter the graph and visualize ---\n",
    "for query, act_data in aggregated.items():\n",
    "    # Build sets of activated node texts and edge texts (strip extra spaces).\n",
    "    activated_node_texts = { node[\"original_text\"].strip() for node in act_data.get(\"nodes\", []) }\n",
    "    activated_edge_texts = { edge[\"original_text\"].strip() for edge in act_data.get(\"edges\", []) }\n",
    "    \n",
    "    # Create a subgraph from the full KG.\n",
    "    H = G.copy()\n",
    "    \n",
    "    # Update nodes: ensure the label is a string and highlight if activated.\n",
    "    for n, data in H.nodes(data=True):\n",
    "        raw_label = data.get(\"label\", \"\")\n",
    "        if isinstance(raw_label, dict):\n",
    "            label = json.dumps(raw_label)\n",
    "        else:\n",
    "            label = str(raw_label)\n",
    "        label = label.strip()\n",
    "        data[\"label\"] = label\n",
    "        data[\"title\"] = label\n",
    "        if label in activated_node_texts:\n",
    "            data[\"color\"] = \"red\"        # highlight color for activated nodes\n",
    "            data[\"borderWidth\"] = 3\n",
    "        else:\n",
    "            data[\"color\"] = \"#97C2FC\"    # default color\n",
    "    \n",
    "    # Update edges: ensure the label is a string and highlight if activated.\n",
    "    for u, v, edata in H.edges(data=True):\n",
    "        raw_rel = edata.get(\"label\", \"\")\n",
    "        if isinstance(raw_rel, dict):\n",
    "            rel = json.dumps(raw_rel)\n",
    "        else:\n",
    "            rel = str(raw_rel)\n",
    "        rel = rel.strip()\n",
    "        edata[\"label\"] = rel\n",
    "        edata[\"title\"] = rel\n",
    "        if rel in activated_edge_texts:\n",
    "            edata[\"color\"] = \"red\"       # highlight activated edge\n",
    "            edata[\"width\"] = 3\n",
    "        else:\n",
    "            edata[\"color\"] = \"gray\"\n",
    "    \n",
    "    # Create a PyVis network with remote CDN resources.\n",
    "    net = Network(height=\"750px\", width=\"100%\", directed=True, cdn_resources=\"remote\", notebook=False)\n",
    "    net.from_nx(H)\n",
    "    \n",
    "    # (Optional) further customize nodes/edges if needed.\n",
    "    for node in net.nodes:\n",
    "        node[\"title\"] = node.get(\"label\", node.get(\"id\", \"\"))\n",
    "        node[\"label\"] = node.get(\"label\", node.get(\"id\", \"\"))\n",
    "    for edge in net.edges:\n",
    "        edge[\"title\"] = edge.get(\"label\", \"\")\n",
    "        edge[\"label\"] = edge.get(\"label\", \"\")\n",
    "    \n",
    "    # Prepare a safe file name from the query.\n",
    "    safe_query = re.sub(r'[^\\w\\s-]', '', query).strip().replace(\" \", \"_\")\n",
    "    output_path = os.path.join(output_dir, f\"{safe_query}.html\")\n",
    "    \n",
    "    # Generate the HTML string and write it to file.\n",
    "    html_str = net.generate_html(notebook=False)\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(html_str)\n",
    "    \n",
    "    webbrowser.open(\"file://\" + os.path.realpath(output_path))\n",
    "    print(f\"Visualization for query:\\n  {query}\\nSaved to: {os.path.realpath(output_path)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8032f8bf-579e-406d-851f-d2943e48e209",
   "metadata": {},
   "source": [
    "# include kg_entities_relations.graphml file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cbf20e71-5217-48e1-bfd0-2a0bcf120882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualization for query:\n",
      "  Summarize Cheerayu Chowhan's work experience at Impact Guru based on the extracted roles, dates, responsibilities, and accomplishments.\n",
      "Saved to: C:\\Users\\cheer\\rv_v1.3\\SOT\\SoT\\query_visualizations\\Summarize_Cheerayu_Chowhans_work_experience_at_Impact_Guru_based_on_the_extracted_roles_dates_responsibilities_and_accomplishments.html\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import networkx as nx\n",
    "from pyvis.network import Network\n",
    "import webbrowser\n",
    "import re\n",
    "\n",
    "# --- File Paths ---\n",
    "graphml_file = \"kg_entities_relations.graphml\"  # Full KG graph (GraphML)\n",
    "query_matches_file = \"query_matches.json\"         # Contains activated nodes for each query\n",
    "output_dir = \"query_visualizations\"               # Directory to save per-query visualizations\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "def load_json(filepath):\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "# --- Load the full KG graph from GraphML ---\n",
    "G = nx.read_graphml(graphml_file)\n",
    "\n",
    "# --- Load query matches to get activated nodes (allowed starting nodes) ---\n",
    "query_matches = load_json(query_matches_file)\n",
    "\n",
    "def get_activated_nodes(query):\n",
    "    activated = set()\n",
    "    if query in query_matches and \"nodes\" in query_matches[query]:\n",
    "        for rec in query_matches[query][\"nodes\"]:\n",
    "            node_id = rec.get(\"kg_node_id\") or rec.get(\"node_id\")\n",
    "            if node_id:\n",
    "                activated.add(node_id)\n",
    "    return activated\n",
    "\n",
    "# --- For each query, update graph visualization to highlight activated nodes ---\n",
    "for query in query_matches.keys():\n",
    "    activated = get_activated_nodes(query)\n",
    "    if not activated:\n",
    "        print(f\"No activated nodes found for query: {query}\")\n",
    "        continue\n",
    "    \n",
    "    # Make a copy of the full graph for visualization\n",
    "    H = G.copy()\n",
    "    \n",
    "    # Set default colors first\n",
    "    for n, data in H.nodes(data=True):\n",
    "        data[\"color\"] = \"#97C2FC\"  # default node color\n",
    "    for u, v, edata in H.edges(data=True):\n",
    "        edata[\"color\"] = \"gray\"   # default edge color\n",
    "        edata[\"width\"] = 1\n",
    "\n",
    "    # Highlight activated nodes in green.\n",
    "    for n in H.nodes:\n",
    "        if n in activated:\n",
    "            H.nodes[n][\"color\"] = \"green\"\n",
    "            H.nodes[n][\"borderWidth\"] = 3\n",
    "    # Optionally, highlight an edge if both endpoints are activated.\n",
    "    for u, v, edata in H.edges(data=True):\n",
    "        if u in activated and v in activated:\n",
    "            edata[\"color\"] = \"green\"\n",
    "            edata[\"width\"] = 3\n",
    "    \n",
    "    # Create a PyVis network using remote resources.\n",
    "    net = Network(height=\"750px\", width=\"100%\", directed=True, cdn_resources=\"remote\", notebook=False)\n",
    "    net.from_nx(H)\n",
    "    \n",
    "    # Customize node appearance.\n",
    "    for node in net.nodes:\n",
    "        node[\"title\"] = node.get(\"label\", node.get(\"id\", \"\"))\n",
    "        node[\"label\"] = node.get(\"label\", node.get(\"id\", \"\"))\n",
    "    for edge in net.edges:\n",
    "        edge[\"title\"] = edge.get(\"label\", \"\")\n",
    "        edge[\"label\"] = edge.get(\"label\", \"\")\n",
    "    \n",
    "    # Prepare a safe file name from the query.\n",
    "    safe_query = re.sub(r'[^\\w\\s-]', '', query).strip().replace(\" \", \"_\")\n",
    "    output_path = os.path.join(output_dir, f\"{safe_query}.html\")\n",
    "    \n",
    "    html_str = net.generate_html(notebook=False)\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(html_str)\n",
    "    \n",
    "    webbrowser.open(\"file://\" + os.path.realpath(output_path))\n",
    "    viz1_path = os.path.realpath(output_path)\n",
    "    print(f\"Visualization for query:\\n  {query}\\nSaved to: {os.path.realpath(output_path)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "357117c3-2429-4c0c-b68f-6201c5fa6289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualization for query:\n",
      "  Summarize Cheerayu Chowhan's work experience at Impact Guru based on the extracted roles, dates, responsibilities, and accomplishments.\n",
      "Saved to: C:\\Users\\cheer\\rv_v1.3\\SOT\\SoT\\query_visualizations\\Summarize_Cheerayu_Chowhans_work_experience_at_Impact_Guru_based_on_the_extracted_roles_dates_responsibilities_and_accomplishments.html\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import networkx as nx\n",
    "from pyvis.network import Network\n",
    "import webbrowser\n",
    "import re\n",
    "\n",
    "# --- File Paths ---\n",
    "graphml_file = \"kg_entities_relations.graphml\"  # Full KG graph (GraphML)\n",
    "query_matches_file = \"query_matches.json\"         # Contains activated nodes for each query\n",
    "output_dir = \"query_visualizations\"               # Directory to save per-query visualizations\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "def load_json(filepath):\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "# --- Load the full KG graph from GraphML ---\n",
    "G = nx.read_graphml(graphml_file)\n",
    "\n",
    "# --- Load query matches to get activated nodes (allowed starting nodes) ---\n",
    "query_matches = load_json(query_matches_file)\n",
    "\n",
    "def get_activated_nodes(query):\n",
    "    activated = set()\n",
    "    if query in query_matches and \"nodes\" in query_matches[query]:\n",
    "        for rec in query_matches[query][\"nodes\"]:\n",
    "            node_id = rec.get(\"kg_node_id\") or rec.get(\"node_id\")\n",
    "            if node_id:\n",
    "                activated.add(node_id)\n",
    "    return activated\n",
    "\n",
    "# --- For each query, update graph visualization to highlight activated nodes ---\n",
    "for query in query_matches.keys():\n",
    "    activated = get_activated_nodes(query)\n",
    "    if not activated:\n",
    "        print(f\"No activated nodes found for query: {query}\")\n",
    "        continue\n",
    "    \n",
    "    # Make a copy of the full graph for visualization\n",
    "    H = G.copy()\n",
    "    \n",
    "    # --- Update node and edge appearance ---\n",
    "    for n, data in H.nodes(data=True):\n",
    "        # Non-activated nodes: light grey, standard size.\n",
    "        data[\"color\"] = \"#D3D3D3\"\n",
    "        data[\"size\"] = 15\n",
    "        # Remove static annotation from non-activated nodes (we will keep title for hover).\n",
    "        data[\"font\"] = {\"size\": 12, \"color\": \"#D3D3D3\"}\n",
    "    \n",
    "    for u, v, edata in H.edges(data=True):\n",
    "        edata[\"color\"] = \"gray\"   # default edge color\n",
    "        edata[\"width\"] = 1\n",
    "\n",
    "    # Highlight activated nodes with larger size and brighter, bigger annotations.\n",
    "    for n in H.nodes:\n",
    "        if n in activated:\n",
    "            H.nodes[n][\"color\"] = \"green\"\n",
    "            H.nodes[n][\"size\"] = 30\n",
    "            H.nodes[n][\"borderWidth\"] = 3\n",
    "            H.nodes[n][\"font\"] = {\"size\": 20, \"color\": \"white\"}  # Bigger static annotation\n",
    "    \n",
    "    # Highlight edges connecting two activated nodes.\n",
    "    for u, v, edata in H.edges(data=True):\n",
    "        if u in activated and v in activated:\n",
    "            edata[\"color\"] = \"green\"\n",
    "            edata[\"width\"] = 3\n",
    "    \n",
    "    # Create a PyVis network with a black background.\n",
    "    net = Network(\n",
    "        height=\"750px\",\n",
    "        width=\"100%\",\n",
    "        directed=True,\n",
    "        cdn_resources=\"remote\",\n",
    "        notebook=False,\n",
    "        bgcolor=\"#000000\"\n",
    "    )\n",
    "    net.from_nx(H)\n",
    "    \n",
    "    # Customize node appearance in the PyVis network.\n",
    "    for node in net.nodes:\n",
    "        # Get the original label from the node data (or use its id).\n",
    "        original_label = node.get(\"label\", node[\"id\"])\n",
    "        if node[\"id\"] in activated:\n",
    "            # For activated nodes: show static label and tooltip.\n",
    "            node[\"title\"] = original_label\n",
    "            node[\"label\"] = original_label\n",
    "        else:\n",
    "            # For non-activated nodes: hide static label, but keep tooltip.\n",
    "            node[\"title\"] = original_label\n",
    "            node[\"label\"] = \"\"\n",
    "    \n",
    "    for edge in net.edges:\n",
    "        edge[\"title\"] = edge.get(\"label\", \"\")\n",
    "        edge[\"label\"] = edge.get(\"label\", \"\")\n",
    "    \n",
    "    # Prepare a safe file name from the query.\n",
    "    safe_query = re.sub(r'[^\\w\\s-]', '', query).strip().replace(\" \", \"_\")\n",
    "    output_path = os.path.join(output_dir, f\"{safe_query}.html\")\n",
    "    \n",
    "    html_str = net.generate_html(notebook=False)\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(html_str)\n",
    "    \n",
    "    webbrowser.open(\"file://\" + os.path.realpath(output_path))\n",
    "    viz1_path = os.path.realpath(output_path)\n",
    "    print(f\"Visualization for query:\\n  {query}\\nSaved to: {viz1_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d44fe8c8-0d7d-4834-9f6d-9764d98edc46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covering (flood fill) visualization for query:\n",
      "  Summarize Cheerayu Chowhan's work experience at Impact Guru based on the extracted roles, dates, responsibilities, and accomplishments.\n",
      "Saved to: C:\\Users\\cheer\\rv_v1.3\\SOT\\SoT\\query_dfs_visualizations\\Summarize_Cheerayu_Chowhans_work_experience_at_Impact_Guru_based_on_the_extracted_roles_dates_responsibilities_and_accomplishments_stcover.html\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import networkx as nx\n",
    "from pyvis.network import Network\n",
    "import webbrowser\n",
    "import re\n",
    "\n",
    "# --- File Paths ---\n",
    "graphml_file = \"kg_entities_relations.graphml\"      # Full KG graph (GraphML)\n",
    "query_matches_file = \"query_matches.json\"             # Contains activated nodes per query\n",
    "output_dir = \"query_dfs_visualizations\"               # Directory to save connectivity visualizations\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "def load_json(filepath):\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def get_activated_nodes(query, query_matches):\n",
    "    activated = set()\n",
    "    if query in query_matches and \"nodes\" in query_matches[query]:\n",
    "        for rec in query_matches[query][\"nodes\"]:\n",
    "            node_id = rec.get(\"kg_node_id\") or rec.get(\"node_id\")\n",
    "            if node_id:\n",
    "                activated.add(node_id)\n",
    "    return activated\n",
    "\n",
    "# --- Load the full KG graph (directed) and convert it to undirected for bidirectional connectivity ---\n",
    "G_directed = nx.read_graphml(graphml_file)\n",
    "G = G_directed  # Keep original for visualization later.\n",
    "G_undirected = G.to_undirected()\n",
    "\n",
    "# --- Load query matches ---\n",
    "query_matches = load_json(query_matches_file)\n",
    "\n",
    "# --- For each query, compute a covering structure that connects as many activated nodes as possible ---\n",
    "for query in query_matches.keys():\n",
    "    activated = get_activated_nodes(query, query_matches)\n",
    "    if not activated:\n",
    "        print(f\"No activated nodes for query: {query}\")\n",
    "        continue\n",
    "\n",
    "    # Find the connected component (in the undirected graph) that contains the majority of activated nodes.\n",
    "    # (If activated nodes span multiple components, we process the largest component.)\n",
    "    comp_dict = {}\n",
    "    for comp in nx.connected_components(G_undirected):\n",
    "        inter = activated & comp\n",
    "        if inter:\n",
    "            comp_dict[frozenset(comp)] = inter\n",
    "    if not comp_dict:\n",
    "        print(f\"No connected component found for activated nodes in query: {query}\")\n",
    "        continue\n",
    "    # Choose the component with maximum activated nodes.\n",
    "    best_comp = max(comp_dict.items(), key=lambda x: len(x[1]))[0]\n",
    "    activated_in_comp = activated & best_comp\n",
    "\n",
    "    # --- Compute metric closure among activated nodes in best_comp ---\n",
    "    # The metric closure is a complete graph where each edge weight is the shortest path distance between activated nodes.\n",
    "    metric_closure = nx.Graph()\n",
    "    activated_list = list(activated_in_comp)\n",
    "    for i in range(len(activated_list)):\n",
    "        for j in range(i+1, len(activated_list)):\n",
    "            u = activated_list[i]\n",
    "            v = activated_list[j]\n",
    "            try:\n",
    "                dist = nx.shortest_path_length(G_undirected, source=u, target=v)\n",
    "                metric_closure.add_edge(u, v, weight=dist)\n",
    "            except nx.NetworkXNoPath:\n",
    "                continue\n",
    "\n",
    "    if metric_closure.number_of_edges() == 0:\n",
    "        print(f\"No connecting paths among activated nodes for query: {query}\")\n",
    "        continue\n",
    "\n",
    "    # --- Compute MST on metric closure ---\n",
    "    mst = nx.minimum_spanning_tree(metric_closure, weight='weight')\n",
    "\n",
    "    # --- Expand MST edges to actual paths in G_undirected ---\n",
    "    steiner_nodes = set()\n",
    "    steiner_edges = set()\n",
    "    for u, v in mst.edges():\n",
    "        try:\n",
    "            sp = nx.shortest_path(G_undirected, source=u, target=v)\n",
    "            steiner_nodes.update(sp)\n",
    "            for i in range(len(sp)-1):\n",
    "                steiner_edges.add((sp[i], sp[i+1]))\n",
    "        except nx.NetworkXNoPath:\n",
    "            continue\n",
    "\n",
    "    # --- Build visualization graph ---\n",
    "    # Start with full graph and grey out everything.\n",
    "    H_full = G.copy()\n",
    "    for n, data in H_full.nodes(data=True):\n",
    "        data[\"color\"] = \"lightgray\"\n",
    "        data[\"borderWidth\"] = 1\n",
    "    for u, v, edata in H_full.edges(data=True):\n",
    "        edata[\"color\"] = \"lightgray\"\n",
    "        edata[\"width\"] = 1\n",
    "\n",
    "    # Now, for nodes:\n",
    "    # - Activated nodes (from query_matches) are green.\n",
    "    # - Nodes in the Steiner tree (steiner_nodes) that are not activated are yellow.\n",
    "    for n in H_full.nodes:\n",
    "        if n in activated:\n",
    "            H_full.nodes[n][\"color\"] = \"green\"\n",
    "            H_full.nodes[n][\"borderWidth\"] = 3\n",
    "        elif n in steiner_nodes:\n",
    "            H_full.nodes[n][\"color\"] = \"yellow\"\n",
    "            H_full.nodes[n][\"borderWidth\"] = 3\n",
    "\n",
    "    # For edges: highlight those that appear in the Steiner tree union in green.\n",
    "    for (u, v) in steiner_edges:\n",
    "        if H_full.has_edge(u, v):\n",
    "            H_full[u][v][\"color\"] = \"green\"\n",
    "            H_full[u][v][\"width\"] = 3\n",
    "        # For undirected behavior, also check reverse edge in the directed graph if applicable.\n",
    "        elif H_full.has_edge(v, u):\n",
    "            H_full[v][u][\"color\"] = \"green\"\n",
    "            H_full[v][u][\"width\"] = 3\n",
    "\n",
    "    # --- Generate visualization with PyVis ---\n",
    "    net = Network(height=\"750px\", width=\"100%\", directed=True, cdn_resources=\"remote\", notebook=False)\n",
    "    net.from_nx(H_full)\n",
    "    \n",
    "    for node in net.nodes:\n",
    "        node[\"title\"] = node.get(\"label\", node.get(\"id\", \"\"))\n",
    "        node[\"label\"] = node.get(\"label\", node.get(\"id\", \"\"))\n",
    "    for edge in net.edges:\n",
    "        edge[\"title\"] = edge.get(\"label\", \"\")\n",
    "        edge[\"label\"] = edge.get(\"label\", \"\")\n",
    "    \n",
    "    safe_query = re.sub(r'[^\\w\\s-]', '', query).strip().replace(\" \", \"_\")\n",
    "    output_path = os.path.join(output_dir, f\"{safe_query}_stcover.html\")\n",
    "    html_str = net.generate_html(notebook=False)\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(html_str)\n",
    "    \n",
    "    webbrowser.open(\"file://\" + os.path.realpath(output_path))\n",
    "    print(f\"Covering (flood fill) visualization for query:\\n  {query}\\nSaved to: {os.path.realpath(output_path)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377dd440-e940-48a0-9291-c063a655bf98",
   "metadata": {},
   "source": [
    "# implementing controlled flow fill implementation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9f8a661b-5478-484e-b2f3-919f63e659b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covering (flood fill) visualization for query:\n",
      "  Summarize Cheerayu Chowhan's work experience at Impact Guru based on the extracted roles, dates, responsibilities, and accomplishments.\n",
      "Saved to: C:\\Users\\cheer\\rv_v1.3\\SOT\\SoT\\query_dfs_visualizations\\Summarize_Cheerayu_Chowhans_work_experience_at_Impact_Guru_based_on_the_extracted_roles_dates_responsibilities_and_accomplishments_stcover.html\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import networkx as nx\n",
    "from pyvis.network import Network\n",
    "import webbrowser\n",
    "import re\n",
    "\n",
    "# --- File Paths ---\n",
    "graphml_file = \"kg_entities_relations.graphml\"      # Full KG graph (GraphML)\n",
    "query_matches_file = \"query_matches.json\"             # Contains activated nodes per query\n",
    "output_dir = \"query_dfs_visualizations\"               # Directory to save connectivity visualizations\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "def load_json(filepath):\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def get_activated_nodes(query, query_matches):\n",
    "    activated = set()\n",
    "    if query in query_matches and \"nodes\" in query_matches[query]:\n",
    "        for rec in query_matches[query][\"nodes\"]:\n",
    "            node_id = rec.get(\"kg_node_id\") or rec.get(\"node_id\")\n",
    "            if node_id:\n",
    "                activated.add(node_id)\n",
    "    return activated\n",
    "\n",
    "# --- Load the full KG graph (directed) and convert it to undirected for bidirectional connectivity ---\n",
    "G_directed = nx.read_graphml(graphml_file)\n",
    "G = G_directed  # Keep original for visualization later.\n",
    "G_undirected = G.to_undirected()\n",
    "\n",
    "# --- Load query matches ---\n",
    "query_matches = load_json(query_matches_file)\n",
    "\n",
    "# --- For each query, compute a covering structure that connects as many activated nodes as possible ---\n",
    "for query in query_matches.keys():\n",
    "    activated = get_activated_nodes(query, query_matches)\n",
    "    if not activated:\n",
    "        print(f\"No activated nodes for query: {query}\")\n",
    "        continue\n",
    "\n",
    "    # Find the connected component (in the undirected graph) that contains the majority of activated nodes.\n",
    "    comp_dict = {}\n",
    "    for comp in nx.connected_components(G_undirected):\n",
    "        inter = activated & comp\n",
    "        if inter:\n",
    "            comp_dict[frozenset(comp)] = inter\n",
    "    if not comp_dict:\n",
    "        print(f\"No connected component found for activated nodes in query: {query}\")\n",
    "        continue\n",
    "    best_comp = max(comp_dict.items(), key=lambda x: len(x[1]))[0]\n",
    "    activated_in_comp = activated & best_comp\n",
    "\n",
    "    # --- Compute metric closure among activated nodes in best_comp ---\n",
    "    metric_closure = nx.Graph()\n",
    "    activated_list = list(activated_in_comp)\n",
    "    for i in range(len(activated_list)):\n",
    "        for j in range(i+1, len(activated_list)):\n",
    "            u = activated_list[i]\n",
    "            v = activated_list[j]\n",
    "            try:\n",
    "                dist = nx.shortest_path_length(G_undirected, source=u, target=v)\n",
    "                metric_closure.add_edge(u, v, weight=dist)\n",
    "            except nx.NetworkXNoPath:\n",
    "                continue\n",
    "\n",
    "    if metric_closure.number_of_edges() == 0:\n",
    "        print(f\"No connecting paths among activated nodes for query: {query}\")\n",
    "        continue\n",
    "\n",
    "    # --- Compute MST on metric closure ---\n",
    "    mst = nx.minimum_spanning_tree(metric_closure, weight='weight')\n",
    "\n",
    "    # --- Expand MST edges to actual paths in G_undirected ---\n",
    "    steiner_nodes = set()\n",
    "    steiner_edges = set()\n",
    "    for u, v in mst.edges():\n",
    "        try:\n",
    "            sp = nx.shortest_path(G_undirected, source=u, target=v)\n",
    "            steiner_nodes.update(sp)\n",
    "            for i in range(len(sp)-1):\n",
    "                steiner_edges.add((sp[i], sp[i+1]))\n",
    "        except nx.NetworkXNoPath:\n",
    "            continue\n",
    "\n",
    "    # --- Build visualization graph ---\n",
    "    H_full = G.copy()\n",
    "    for n, data in H_full.nodes(data=True):\n",
    "        data[\"color\"] = \"lightgray\"\n",
    "        data[\"borderWidth\"] = 1\n",
    "    for u, v, edata in H_full.edges(data=True):\n",
    "        edata[\"color\"] = \"lightgray\"\n",
    "        edata[\"width\"] = 1\n",
    "\n",
    "    # Color nodes:\n",
    "    # Activated nodes (from query_matches) in green.\n",
    "    # Steiner tree nodes (that are not activated) in yellow.\n",
    "    for n in H_full.nodes:\n",
    "        if n in activated:\n",
    "            H_full.nodes[n][\"color\"] = \"green\"\n",
    "            H_full.nodes[n][\"borderWidth\"] = 3\n",
    "        elif n in steiner_nodes:\n",
    "            H_full.nodes[n][\"color\"] = \"yellow\"\n",
    "            H_full.nodes[n][\"borderWidth\"] = 3\n",
    "\n",
    "    # Color edges in the Steiner tree union in green.\n",
    "    for (u, v) in steiner_edges:\n",
    "        if H_full.has_edge(u, v):\n",
    "            H_full[u][v][\"color\"] = \"green\"\n",
    "            H_full[u][v][\"width\"] = 3\n",
    "        elif H_full.has_edge(v, u):\n",
    "            H_full[v][u][\"color\"] = \"green\"\n",
    "            H_full[v][u][\"width\"] = 3\n",
    "\n",
    "    # --- Additional: Mark red edges for any direct connection between nodes in (activated U steiner_nodes)\n",
    "    union_nodes = activated.union(steiner_nodes)\n",
    "    for u, v, edata in H_full.edges(data=True):\n",
    "        if u in union_nodes and v in union_nodes:\n",
    "            # If not already green, mark edge red.\n",
    "            if edata.get(\"color\") != \"green\":\n",
    "                edata[\"color\"] = \"red\"\n",
    "                edata[\"width\"] = 2\n",
    "\n",
    "    # --- Generate visualization with PyVis ---\n",
    "    net = Network(height=\"750px\", width=\"100%\", directed=True, cdn_resources=\"remote\", notebook=False)\n",
    "    net.from_nx(H_full)\n",
    "    \n",
    "    for node in net.nodes:\n",
    "        node[\"title\"] = node.get(\"label\", node.get(\"id\", \"\"))\n",
    "        node[\"label\"] = node.get(\"label\", node.get(\"id\", \"\"))\n",
    "    for edge in net.edges:\n",
    "        edge[\"title\"] = edge.get(\"label\", \"\")\n",
    "        edge[\"label\"] = edge.get(\"label\", \"\")\n",
    "    \n",
    "    safe_query = re.sub(r'[^\\w\\s-]', '', query).strip().replace(\" \", \"_\")\n",
    "    output_path = os.path.join(output_dir, f\"{safe_query}_stcover.html\")\n",
    "    html_str = net.generate_html(notebook=False)\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(html_str)\n",
    "    \n",
    "    webbrowser.open(\"file://\" + os.path.realpath(output_path))\n",
    "    print(f\"Covering (flood fill) visualization for query:\\n  {query}\\nSaved to: {os.path.realpath(output_path)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c5d560e4-adff-46b1-b072-77ee5d4a3e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved sequence for query:\n",
      "  Summarize Cheerayu Chowhan's work experience at Impact Guru based on the extracted roles, dates, responsibilities, and accomplishments.\n",
      "Saved to: C:\\Users\\cheer\\rv_v1.3\\SOT\\SoT\\retrieved_sequences\\Summarize_Cheerayu_Chowhans_work_experience_at_Impact_Guru_based_on_the_extracted_roles_dates_responsibilities_and_accomplishments_sequence.json\n",
      "Covering (flood fill) visualization for query:\n",
      "  Summarize Cheerayu Chowhan's work experience at Impact Guru based on the extracted roles, dates, responsibilities, and accomplishments.\n",
      "Saved to: C:\\Users\\cheer\\rv_v1.3\\SOT\\SoT\\query_dfs_visualizations\\Summarize_Cheerayu_Chowhans_work_experience_at_Impact_Guru_based_on_the_extracted_roles_dates_responsibilities_and_accomplishments_stcover.html\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import networkx as nx\n",
    "from pyvis.network import Network\n",
    "import webbrowser\n",
    "import re\n",
    "\n",
    "# --- File Paths ---\n",
    "graphml_file = \"kg_entities_relations.graphml\"      # Full KG graph (GraphML)\n",
    "query_matches_file = \"query_matches.json\"             # Contains activated nodes (with similarity) per query\n",
    "output_dir = \"query_dfs_visualizations\"               # Directory to save connectivity visualizations\n",
    "sequence_output_dir = \"retrieved_sequences\"           # Directory to save the ordered retrieved knowledge JSONs\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "os.makedirs(sequence_output_dir, exist_ok=True)\n",
    "\n",
    "def load_json(filepath):\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def get_activated_nodes(query, query_matches):\n",
    "    \"\"\"\n",
    "    Returns a set of activated node IDs (using 'kg_node_id' or 'node_id')\n",
    "    and also returns the record with the highest similarity among activated nodes.\n",
    "    \"\"\"\n",
    "    activated = set()\n",
    "    best_record = None\n",
    "    best_sim = -1\n",
    "    if query in query_matches and \"nodes\" in query_matches[query]:\n",
    "        for rec in query_matches[query][\"nodes\"]:\n",
    "            node_id = rec.get(\"kg_node_id\") or rec.get(\"node_id\")\n",
    "            if node_id:\n",
    "                activated.add(node_id)\n",
    "                sim = rec.get(\"similarity\", 0)\n",
    "                if sim > best_sim:\n",
    "                    best_sim = sim\n",
    "                    best_record = rec\n",
    "    return activated, best_record\n",
    "\n",
    "# --- Load the full KG graph (directed) and also create an undirected version ---\n",
    "G_directed = nx.read_graphml(graphml_file)\n",
    "G = G_directed  # We'll use the directed graph for visualization later.\n",
    "G_undirected = G.to_undirected()\n",
    "\n",
    "# --- Load query matches ---\n",
    "query_matches = load_json(query_matches_file)\n",
    "\n",
    "# --- Build the interconnected subgraph as before (Steiner tree approximation) ---\n",
    "for query in query_matches.keys():\n",
    "    activated, best_rec = get_activated_nodes(query, query_matches)\n",
    "    if not activated:\n",
    "        print(f\"No activated nodes for query: {query}\")\n",
    "        continue\n",
    "\n",
    "    # Find the connected component in G_undirected that contains the majority of activated nodes.\n",
    "    comp_dict = {}\n",
    "    for comp in nx.connected_components(G_undirected):\n",
    "        inter = activated & comp\n",
    "        if inter:\n",
    "            comp_dict[frozenset(comp)] = inter\n",
    "    if not comp_dict:\n",
    "        print(f\"No connected component found for activated nodes in query: {query}\")\n",
    "        continue\n",
    "    best_comp = max(comp_dict.items(), key=lambda x: len(x[1]))[0]\n",
    "    activated_in_comp = activated & best_comp\n",
    "\n",
    "    # Compute metric closure among activated nodes in best_comp.\n",
    "    metric_closure = nx.Graph()\n",
    "    activated_list = list(activated_in_comp)\n",
    "    for i in range(len(activated_list)):\n",
    "        for j in range(i+1, len(activated_list)):\n",
    "            u = activated_list[i]\n",
    "            v = activated_list[j]\n",
    "            try:\n",
    "                dist = nx.shortest_path_length(G_undirected, source=u, target=v)\n",
    "                metric_closure.add_edge(u, v, weight=dist)\n",
    "            except nx.NetworkXNoPath:\n",
    "                continue\n",
    "    if metric_closure.number_of_edges() == 0:\n",
    "        print(f\"No connecting paths among activated nodes for query: {query}\")\n",
    "        continue\n",
    "\n",
    "    # Compute MST on metric closure.\n",
    "    mst = nx.minimum_spanning_tree(metric_closure, weight='weight')\n",
    "\n",
    "    # Expand MST edges to actual paths in G_undirected (Steiner Tree Approximation).\n",
    "    steiner_nodes = set()\n",
    "    steiner_edges = set()\n",
    "    for u, v in mst.edges():\n",
    "        try:\n",
    "            sp = nx.shortest_path(G_undirected, source=u, target=v)\n",
    "            steiner_nodes.update(sp)\n",
    "            for i in range(len(sp)-1):\n",
    "                steiner_edges.add((sp[i], sp[i+1]))\n",
    "        except nx.NetworkXNoPath:\n",
    "            continue\n",
    "\n",
    "    # --- Build visualization graph (H_full) as before ---\n",
    "    H_full = G.copy()\n",
    "    for n, data in H_full.nodes(data=True):\n",
    "        data[\"color\"] = \"lightgray\"\n",
    "        data[\"borderWidth\"] = 1\n",
    "    for u, v, edata in H_full.edges(data=True):\n",
    "        edata[\"color\"] = \"lightgray\"\n",
    "        edata[\"width\"] = 1\n",
    "\n",
    "    # Color nodes:\n",
    "    # Activated nodes are green.\n",
    "    # Steiner nodes (not activated) are yellow.\n",
    "    for n in H_full.nodes:\n",
    "        if n in activated:\n",
    "            H_full.nodes[n][\"color\"] = \"green\"\n",
    "            H_full.nodes[n][\"borderWidth\"] = 3\n",
    "        elif n in steiner_nodes:\n",
    "            H_full.nodes[n][\"color\"] = \"yellow\"\n",
    "            H_full.nodes[n][\"borderWidth\"] = 3\n",
    "\n",
    "    # Color edges that are in the Steiner tree union in green.\n",
    "    for (u, v) in steiner_edges:\n",
    "        if H_full.has_edge(u, v):\n",
    "            H_full[u][v][\"color\"] = \"green\"\n",
    "            H_full[u][v][\"width\"] = 3\n",
    "        elif H_full.has_edge(v, u):\n",
    "            H_full[v][u][\"color\"] = \"green\"\n",
    "            H_full[v][u][\"width\"] = 3\n",
    "\n",
    "    # Mark red edges: any direct connection (single edge) between any two nodes in (activated U steiner_nodes)\n",
    "    union_nodes = activated.union(steiner_nodes)\n",
    "    for u, v, edata in H_full.edges(data=True):\n",
    "        if u in union_nodes and v in union_nodes:\n",
    "            if edata.get(\"color\") != \"green\":\n",
    "                edata[\"color\"] = \"red\"\n",
    "                edata[\"width\"] = 2\n",
    "\n",
    "    # --- Filter to keep only the interconnected subgraph among union_nodes ---\n",
    "    H_union = H_full.subgraph(union_nodes).copy()\n",
    "    if len(H_union.nodes()) > 0:\n",
    "        comps = list(nx.connected_components(H_union.to_undirected()))\n",
    "        if comps:\n",
    "            largest_comp = max(comps, key=len)\n",
    "            H_union = H_union.subgraph(largest_comp).copy()\n",
    "    # Remove nodes with degree < 2 to avoid isolated parts.\n",
    "    nodes_to_remove = [n for n in H_union.nodes() if H_union.degree(n) < 2]\n",
    "    H_union.remove_nodes_from(nodes_to_remove)\n",
    "\n",
    "    # Merge H_union back into H_full (grey out nodes not in H_union).\n",
    "    for n in H_full.nodes:\n",
    "        if n not in H_union.nodes():\n",
    "            H_full.nodes[n][\"color\"] = \"lightgray\"\n",
    "            H_full.nodes[n][\"borderWidth\"] = 1\n",
    "\n",
    "    # --- Now, instead of ranking by information score, we produce an ordered sequence.\n",
    "    # We want to start at a \"starting point\" from query_matches.json that is most similar.\n",
    "    # We'll choose the node from query_matches[query][\"nodes\"] with highest \"similarity\".\n",
    "    starting_node = None\n",
    "    best_sim = -1\n",
    "    if query in query_matches and \"nodes\" in query_matches[query]:\n",
    "        for rec in query_matches[query][\"nodes\"]:\n",
    "            sim = rec.get(\"similarity\", 0)\n",
    "            if sim > best_sim:\n",
    "                best_sim = sim\n",
    "                starting_node = rec.get(\"kg_node_id\") or rec.get(\"node_id\")\n",
    "    if starting_node is None or starting_node not in H_union.nodes():\n",
    "        # Fallback: choose an arbitrary node from H_union.\n",
    "        if len(H_union.nodes()) > 0:\n",
    "            starting_node = list(H_union.nodes())[0]\n",
    "        else:\n",
    "            print(f\"No interconnected subgraph available for query: {query}\")\n",
    "            continue\n",
    "\n",
    "    # --- Perform a DFS traversal over H_union starting at starting_node.\n",
    "    # We treat H_union as undirected for DFS to cover all nodes.\n",
    "    dfs_nodes = list(nx.dfs_preorder_nodes(H_union.to_undirected(), source=starting_node))\n",
    "    \n",
    "    # For each consecutive pair in DFS order, find the direct edge in H_union (if available).\n",
    "    sequence = []\n",
    "    # Record the starting node.\n",
    "    for node in dfs_nodes:\n",
    "        data = H_union.nodes[node]\n",
    "        text = \"\"\n",
    "        if \"payload\" in data and isinstance(data[\"payload\"], dict):\n",
    "            text = data[\"payload\"].get(\"text\", \"\")\n",
    "        if not text:\n",
    "            text = data.get(\"label\", node)\n",
    "        sequence.append({\"type\": \"node\", \"id\": node, \"text\": text, \"color\": data.get(\"color\")})\n",
    "        # If not the last node, add the edge info.\n",
    "        if node != dfs_nodes[-1]:\n",
    "            # Get the next node.\n",
    "            next_node = dfs_nodes[dfs_nodes.index(node)+1]\n",
    "            # Try to get edge data from H_union.\n",
    "            edge_data = None\n",
    "            if H_union.has_edge(node, next_node):\n",
    "                edge_data = H_union.get_edge_data(node, next_node)\n",
    "            elif H_union.has_edge(next_node, node):\n",
    "                edge_data = H_union.get_edge_data(next_node, node)\n",
    "            edge_text = \"\"\n",
    "            if edge_data:\n",
    "                edge_text = edge_data.get(\"label\", \"\")\n",
    "            sequence.append({\n",
    "                \"type\": \"edge\",\n",
    "                \"from\": node,\n",
    "                \"to\": next_node,\n",
    "                \"text\": edge_text,\n",
    "                \"color\": edge_data.get(\"color\") if edge_data else \"\"\n",
    "            })\n",
    "    \n",
    "    # Save the retrieved sequence to a JSON file.\n",
    "    safe_query = re.sub(r'[^\\w\\s-]', '', query).strip().replace(\" \", \"_\")\n",
    "    sequence_output_path = os.path.join(sequence_output_dir, f\"{safe_query}_sequence.json\")\n",
    "    with open(sequence_output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(sequence, f, indent=2)\n",
    "    \n",
    "    print(f\"Retrieved sequence for query:\\n  {query}\\nSaved to: {os.path.realpath(sequence_output_path)}\")\n",
    "    \n",
    "    # --- Generate Visualization with PyVis (as before) ---\n",
    "    net = Network(height=\"750px\", width=\"100%\", directed=True, cdn_resources=\"remote\", notebook=False)\n",
    "    net.from_nx(H_full)\n",
    "    for node in net.nodes:\n",
    "        node[\"title\"] = node.get(\"label\", node.get(\"id\", \"\"))\n",
    "        node[\"label\"] = node.get(\"label\", node.get(\"id\", \"\"))\n",
    "    for edge in net.edges:\n",
    "        edge[\"title\"] = edge.get(\"label\", \"\")\n",
    "        edge[\"label\"] = edge.get(\"label\", \"\")\n",
    "    vis_output_path = os.path.join(output_dir, f\"{safe_query}_stcover.html\")\n",
    "    html_str = net.generate_html(notebook=False)\n",
    "    with open(vis_output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(html_str)\n",
    "    webbrowser.open(\"file://\" + os.path.realpath(vis_output_path))\n",
    "    print(f\"Covering (flood fill) visualization for query:\\n  {query}\\nSaved to: {os.path.realpath(vis_output_path)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "800d21d8-eb8d-4b75-9acb-e3ed7ccd815a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved sequence for query:\n",
      "  Summarize Cheerayu Chowhan's work experience at Impact Guru based on the extracted roles, dates, responsibilities, and accomplishments.\n",
      "Saved to: C:\\Users\\cheer\\rv_v1.3\\SOT\\SoT\\retrieved_sequences\\Summarize_Cheerayu_Chowhans_work_experience_at_Impact_Guru_based_on_the_extracted_roles_dates_responsibilities_and_accomplishments_sequence.json\n",
      "Covering (flood fill) visualization for query:\n",
      "  Summarize Cheerayu Chowhan's work experience at Impact Guru based on the extracted roles, dates, responsibilities, and accomplishments.\n",
      "Saved to: C:\\Users\\cheer\\rv_v1.3\\SOT\\SoT\\query_dfs_visualizations\\Summarize_Cheerayu_Chowhans_work_experience_at_Impact_Guru_based_on_the_extracted_roles_dates_responsibilities_and_accomplishments_stcover.html\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import networkx as nx\n",
    "from pyvis.network import Network\n",
    "import webbrowser\n",
    "import re\n",
    "\n",
    "# --- File Paths ---\n",
    "graphml_file = \"kg_entities_relations.graphml\"      # Full KG graph (GraphML)\n",
    "query_matches_file = \"query_matches.json\"             # Contains activated nodes (with similarity) per query\n",
    "output_dir = \"query_dfs_visualizations\"               # Directory to save connectivity visualizations\n",
    "sequence_output_dir = \"retrieved_sequences\"           # Directory to save the ordered retrieved knowledge JSONs\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "os.makedirs(sequence_output_dir, exist_ok=True)\n",
    "\n",
    "def load_json(filepath):\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def get_activated_nodes(query, query_matches):\n",
    "    \"\"\"\n",
    "    Returns a set of activated node IDs (using 'kg_node_id' or 'node_id')\n",
    "    and also returns the record with the highest similarity among activated nodes.\n",
    "    \"\"\"\n",
    "    activated = set()\n",
    "    best_record = None\n",
    "    best_sim = -1\n",
    "    if query in query_matches and \"nodes\" in query_matches[query]:\n",
    "        for rec in query_matches[query][\"nodes\"]:\n",
    "            node_id = rec.get(\"kg_node_id\") or rec.get(\"node_id\")\n",
    "            if node_id:\n",
    "                activated.add(node_id)\n",
    "                sim = rec.get(\"similarity\", 0)\n",
    "                if sim > best_sim:\n",
    "                    best_sim = sim\n",
    "                    best_record = rec\n",
    "    return activated, best_record\n",
    "\n",
    "# --- Load the full KG graph (directed) and also create an undirected version ---\n",
    "G_directed = nx.read_graphml(graphml_file)\n",
    "G = G_directed  # We'll use the directed graph for visualization later.\n",
    "G_undirected = G.to_undirected()\n",
    "\n",
    "# --- Load query matches ---\n",
    "query_matches = load_json(query_matches_file)\n",
    "\n",
    "# --- Compute the interconnected subgraph (Steiner Tree approximation) as before ---\n",
    "for query in query_matches.keys():\n",
    "    activated, best_rec = get_activated_nodes(query, query_matches)\n",
    "    if not activated:\n",
    "        print(f\"No activated nodes for query: {query}\")\n",
    "        continue\n",
    "\n",
    "    # Find the connected component in G_undirected that contains the majority of activated nodes.\n",
    "    comp_dict = {}\n",
    "    for comp in nx.connected_components(G_undirected):\n",
    "        inter = activated & comp\n",
    "        if inter:\n",
    "            comp_dict[frozenset(comp)] = inter\n",
    "    if not comp_dict:\n",
    "        print(f\"No connected component found for activated nodes in query: {query}\")\n",
    "        continue\n",
    "    best_comp = max(comp_dict.items(), key=lambda x: len(x[1]))[0]\n",
    "    activated_in_comp = activated & best_comp\n",
    "\n",
    "    # --- Compute metric closure among activated nodes in best_comp ---\n",
    "    metric_closure = nx.Graph()\n",
    "    activated_list = list(activated_in_comp)\n",
    "    for i in range(len(activated_list)):\n",
    "        for j in range(i+1, len(activated_list)):\n",
    "            u = activated_list[i]\n",
    "            v = activated_list[j]\n",
    "            try:\n",
    "                dist = nx.shortest_path_length(G_undirected, source=u, target=v)\n",
    "                metric_closure.add_edge(u, v, weight=dist)\n",
    "            except nx.NetworkXNoPath:\n",
    "                continue\n",
    "    if metric_closure.number_of_edges() == 0:\n",
    "        print(f\"No connecting paths among activated nodes for query: {query}\")\n",
    "        continue\n",
    "\n",
    "    # --- Compute MST on metric closure ---\n",
    "    mst = nx.minimum_spanning_tree(metric_closure, weight='weight')\n",
    "\n",
    "    # --- Expand MST edges to actual paths in G_undirected (Steiner Tree Approximation) ---\n",
    "    steiner_nodes = set()\n",
    "    steiner_edges = set()\n",
    "    for u, v in mst.edges():\n",
    "        try:\n",
    "            sp = nx.shortest_path(G_undirected, source=u, target=v)\n",
    "            steiner_nodes.update(sp)\n",
    "            for i in range(len(sp)-1):\n",
    "                steiner_edges.add((sp[i], sp[i+1]))\n",
    "        except nx.NetworkXNoPath:\n",
    "            continue\n",
    "\n",
    "    # --- Build visualization graph (H_full) ---\n",
    "    H_full = G.copy()\n",
    "    for n, data in H_full.nodes(data=True):\n",
    "        data[\"color\"] = \"lightgray\"\n",
    "        data[\"borderWidth\"] = 1\n",
    "    for u, v, edata in H_full.edges(data=True):\n",
    "        edata[\"color\"] = \"lightgray\"\n",
    "        edata[\"width\"] = 1\n",
    "\n",
    "    # Color nodes:\n",
    "    # - Activated nodes (from query_matches) are green.\n",
    "    # - Nodes in the Steiner tree (steiner_nodes) that are not activated are yellow.\n",
    "    for n in H_full.nodes:\n",
    "        if n in activated:\n",
    "            H_full.nodes[n][\"color\"] = \"green\"\n",
    "            H_full.nodes[n][\"borderWidth\"] = 3\n",
    "        elif n in steiner_nodes:\n",
    "            H_full.nodes[n][\"color\"] = \"yellow\"\n",
    "            H_full.nodes[n][\"borderWidth\"] = 3\n",
    "\n",
    "    # Color edges that are part of the Steiner tree union in green.\n",
    "    for (u, v) in steiner_edges:\n",
    "        if H_full.has_edge(u, v):\n",
    "            H_full[u][v][\"color\"] = \"green\"\n",
    "            H_full[u][v][\"width\"] = 3\n",
    "        elif H_full.has_edge(v, u):\n",
    "            H_full[v][u][\"color\"] = \"green\"\n",
    "            H_full[v][u][\"width\"] = 3\n",
    "\n",
    "    # --- Additional: Mark red edges for any direct connection between nodes in the union ---\n",
    "    union_nodes = activated.union(steiner_nodes)\n",
    "    for u, v, edata in H_full.edges(data=True):\n",
    "        if u in union_nodes and v in union_nodes:\n",
    "            if edata.get(\"color\") != \"green\":\n",
    "                edata[\"color\"] = \"red\"\n",
    "                edata[\"width\"] = 2\n",
    "\n",
    "    # --- Filter to keep only the interconnected subgraph among union_nodes ---\n",
    "    H_union = H_full.subgraph(union_nodes).copy()\n",
    "    if len(H_union.nodes()) > 0:\n",
    "        comps = list(nx.connected_components(H_union.to_undirected()))\n",
    "        if comps:\n",
    "            largest_comp = max(comps, key=len)\n",
    "            H_union = H_union.subgraph(largest_comp).copy()\n",
    "    # Remove nodes with degree < 2 to avoid isolated parts.\n",
    "    nodes_to_remove = [n for n in H_union.nodes() if H_union.degree(n) < 2]\n",
    "    H_union.remove_nodes_from(nodes_to_remove)\n",
    "\n",
    "    # Merge H_union back into H_full (grey out nodes not in H_union).\n",
    "    for n in H_full.nodes:\n",
    "        if n not in H_union.nodes():\n",
    "            H_full.nodes[n][\"color\"] = \"lightgray\"\n",
    "            H_full.nodes[n][\"borderWidth\"] = 1\n",
    "\n",
    "    # --- Sequence Extraction via DFS Traversal ---\n",
    "    # Choose starting node from query_matches with highest similarity.\n",
    "    starting_node = None\n",
    "    best_sim = -1\n",
    "    if query in query_matches and \"nodes\" in query_matches[query]:\n",
    "        for rec in query_matches[query][\"nodes\"]:\n",
    "            sim = rec.get(\"similarity\", 0)\n",
    "            if sim > best_sim:\n",
    "                best_sim = sim\n",
    "                starting_node = rec.get(\"kg_node_id\") or rec.get(\"node_id\")\n",
    "    if starting_node is None or starting_node not in H_union.nodes():\n",
    "        if len(H_union.nodes()) > 0:\n",
    "            starting_node = list(H_union.nodes())[0]\n",
    "        else:\n",
    "            print(f\"No interconnected subgraph available for query: {query}\")\n",
    "            continue\n",
    "\n",
    "    # Perform DFS traversal on H_union (treated as undirected) to get an ordered sequence.\n",
    "    dfs_nodes = list(nx.dfs_preorder_nodes(H_union.to_undirected(), source=starting_node))\n",
    "    \n",
    "    # Build an ordered sequence: for each node (include its text and chunk_ids), then each edge.\n",
    "    sequence = []\n",
    "    for idx, node in enumerate(dfs_nodes):\n",
    "        data = H_union.nodes[node]\n",
    "        # Extract text and chunk_ids from payload if available.\n",
    "        text = \"\"\n",
    "        chunk_ids = []\n",
    "        if \"payload\" in data and isinstance(data[\"payload\"], dict):\n",
    "            text = data[\"payload\"].get(\"text\", \"\")\n",
    "            chunk_ids = data[\"payload\"].get(\"chunk_ids\", [])\n",
    "        if not text:\n",
    "            text = data.get(\"label\", node)\n",
    "        sequence.append({\n",
    "            \"type\": \"node\",\n",
    "            \"id\": node,\n",
    "            \"text\": text,\n",
    "            \"color\": data.get(\"color\"),\n",
    "            \"chunk_ids\": chunk_ids\n",
    "        })\n",
    "        # For consecutive nodes, try to record the edge connecting them.\n",
    "        if idx < len(dfs_nodes) - 1:\n",
    "            next_node = dfs_nodes[idx + 1]\n",
    "            edge_data = None\n",
    "            if H_union.has_edge(node, next_node):\n",
    "                edge_data = H_union.get_edge_data(node, next_node)\n",
    "            elif H_union.has_edge(next_node, node):\n",
    "                edge_data = H_union.get_edge_data(next_node, node)\n",
    "            edge_text = \"\"\n",
    "            edge_chunk_ids = []\n",
    "            if edge_data:\n",
    "                edge_text = edge_data.get(\"label\", \"\")\n",
    "                edge_chunk_ids = edge_data.get(\"chunk_ids\", [])\n",
    "            sequence.append({\n",
    "                \"type\": \"edge\",\n",
    "                \"from\": node,\n",
    "                \"to\": next_node,\n",
    "                \"text\": edge_text,\n",
    "                \"color\": edge_data.get(\"color\") if edge_data else \"\",\n",
    "                \"chunk_ids\": edge_chunk_ids\n",
    "            })\n",
    "\n",
    "    # Save the retrieved sequence to a JSON file.\n",
    "    safe_query = re.sub(r'[^\\w\\s-]', '', query).strip().replace(\" \", \"_\")\n",
    "    sequence_output_path = os.path.join(sequence_output_dir, f\"{safe_query}_sequence.json\")\n",
    "    with open(sequence_output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(sequence, f, indent=2)\n",
    "    \n",
    "    print(f\"Retrieved sequence for query:\\n  {query}\\nSaved to: {os.path.realpath(sequence_output_path)}\")\n",
    "    \n",
    "    # --- Generate Visualization with PyVis ---\n",
    "    net = Network(height=\"750px\", width=\"100%\", directed=True, cdn_resources=\"remote\", notebook=False)\n",
    "    net.from_nx(H_full)\n",
    "    for node in net.nodes:\n",
    "        node[\"title\"] = node.get(\"label\", node.get(\"id\", \"\"))\n",
    "        node[\"label\"] = node.get(\"label\", node.get(\"id\", \"\"))\n",
    "    for edge in net.edges:\n",
    "        edge[\"title\"] = edge.get(\"label\", \"\")\n",
    "        edge[\"label\"] = edge.get(\"label\", \"\")\n",
    "    vis_output_path = os.path.join(output_dir, f\"{safe_query}_stcover.html\")\n",
    "    html_str = net.generate_html(notebook=False)\n",
    "    with open(vis_output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(html_str)\n",
    "    webbrowser.open(\"file://\" + os.path.realpath(vis_output_path))\n",
    "    print(f\"Covering (flood fill) visualization for query:\\n  {query}\\nSaved to: {os.path.realpath(vis_output_path)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7ee4d7e0-18f8-47fe-ab7b-a8ecb9e3b7a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved sequence for query:\n",
      "  Summarize Cheerayu Chowhan's work experience at Impact Guru based on the extracted roles, dates, responsibilities, and accomplishments.\n",
      "Saved to: C:\\Users\\cheer\\rv_v1.3\\SOT\\SoT\\retrieved_sequences\\Summarize_Cheerayu_Chowhans_work_experience_at_Impact_Guru_based_on_the_extracted_roles_dates_responsibilities_and_accomplishments_sequence.json\n",
      "Covering (flood fill) visualization for query:\n",
      "  Summarize Cheerayu Chowhan's work experience at Impact Guru based on the extracted roles, dates, responsibilities, and accomplishments.\n",
      "Saved to: C:\\Users\\cheer\\rv_v1.3\\SOT\\SoT\\query_dfs_visualizations\\Summarize_Cheerayu_Chowhans_work_experience_at_Impact_Guru_based_on_the_extracted_roles_dates_responsibilities_and_accomplishments_stcover.html\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import networkx as nx\n",
    "from pyvis.network import Network\n",
    "import webbrowser\n",
    "import re\n",
    "\n",
    "# --- File Paths ---\n",
    "graphml_file = \"kg_entities_relations.graphml\"      # Full KG graph (GraphML)\n",
    "query_matches_file = \"query_matches.json\"             # Contains activated nodes (with similarity) per query\n",
    "matching_nodes_edges_file = \"matching_nodes_edges.json\"  # File with nodes/edges and their chunk_ids\n",
    "output_dir = \"query_dfs_visualizations\"               # Directory to save connectivity visualizations\n",
    "sequence_output_dir = \"retrieved_sequences\"           # Directory to save the ordered retrieved knowledge JSONs\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "os.makedirs(sequence_output_dir, exist_ok=True)\n",
    "\n",
    "def load_json(filepath):\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def get_activated_nodes(query, query_matches):\n",
    "    \"\"\"\n",
    "    Returns a set of activated node IDs (using 'kg_node_id' or 'node_id')\n",
    "    and also returns the record with the highest similarity among activated nodes.\n",
    "    \"\"\"\n",
    "    activated = set()\n",
    "    best_record = None\n",
    "    best_sim = -1\n",
    "    if query in query_matches and \"nodes\" in query_matches[query]:\n",
    "        for rec in query_matches[query][\"nodes\"]:\n",
    "            node_id = rec.get(\"kg_node_id\") or rec.get(\"node_id\")\n",
    "            if node_id:\n",
    "                activated.add(node_id)\n",
    "                sim = rec.get(\"similarity\", 0)\n",
    "                if sim > best_sim:\n",
    "                    best_sim = sim\n",
    "                    best_record = rec\n",
    "    return activated, best_record\n",
    "\n",
    "# --- Load the full KG graph (directed) and also create an undirected version ---\n",
    "G_directed = nx.read_graphml(graphml_file)\n",
    "G = G_directed  # We'll use the directed graph for visualization later.\n",
    "G_undirected = G.to_undirected()\n",
    "\n",
    "# --- Load query matches ---\n",
    "query_matches = load_json(query_matches_file)\n",
    "# --- Load matching nodes/edges to get chunk references if needed ---\n",
    "matching_nodes_edges = load_json(matching_nodes_edges_file)\n",
    "\n",
    "# For current query, build mapping for nodes and edges from matching file.\n",
    "def build_matching_mappings(query, matching_data):\n",
    "    node_map = {}\n",
    "    edge_map = {}\n",
    "    if query in matching_data:\n",
    "        qdata = matching_data[query]\n",
    "        if \"nodes\" in qdata:\n",
    "            for rec in qdata[\"nodes\"]:\n",
    "                nid = rec.get(\"kg_node_id\") or rec.get(\"node_id\")\n",
    "                if nid:\n",
    "                    node_map[nid] = rec.get(\"chunk_ids\", [])\n",
    "        if \"edges\" in qdata:\n",
    "            for rec in qdata[\"edges\"]:\n",
    "                eid = rec.get(\"kg_edge_id\") or rec.get(\"edge_id\")\n",
    "                # Alternatively, you may define a key as \"from--to\" if no id exists.\n",
    "                if eid:\n",
    "                    edge_map[eid] = rec.get(\"chunk_ids\", [])\n",
    "    return node_map, edge_map\n",
    "\n",
    "# --- Compute the interconnected subgraph as before (Steiner Tree approximation) ---\n",
    "for query in query_matches.keys():\n",
    "    activated, best_rec = get_activated_nodes(query, query_matches)\n",
    "    if not activated:\n",
    "        print(f\"No activated nodes for query: {query}\")\n",
    "        continue\n",
    "\n",
    "    # Find the connected component in G_undirected that contains the majority of activated nodes.\n",
    "    comp_dict = {}\n",
    "    for comp in nx.connected_components(G_undirected):\n",
    "        inter = activated & comp\n",
    "        if inter:\n",
    "            comp_dict[frozenset(comp)] = inter\n",
    "    if not comp_dict:\n",
    "        print(f\"No connected component found for activated nodes in query: {query}\")\n",
    "        continue\n",
    "    best_comp = max(comp_dict.items(), key=lambda x: len(x[1]))[0]\n",
    "    activated_in_comp = activated & best_comp\n",
    "\n",
    "    # --- Compute metric closure among activated nodes in best_comp ---\n",
    "    metric_closure = nx.Graph()\n",
    "    activated_list = list(activated_in_comp)\n",
    "    for i in range(len(activated_list)):\n",
    "        for j in range(i+1, len(activated_list)):\n",
    "            u = activated_list[i]\n",
    "            v = activated_list[j]\n",
    "            try:\n",
    "                dist = nx.shortest_path_length(G_undirected, source=u, target=v)\n",
    "                metric_closure.add_edge(u, v, weight=dist)\n",
    "            except nx.NetworkXNoPath:\n",
    "                continue\n",
    "    if metric_closure.number_of_edges() == 0:\n",
    "        print(f\"No connecting paths among activated nodes for query: {query}\")\n",
    "        continue\n",
    "\n",
    "    # --- Compute MST on metric closure ---\n",
    "    mst = nx.minimum_spanning_tree(metric_closure, weight='weight')\n",
    "\n",
    "    # --- Expand MST edges to actual paths in G_undirected (Steiner Tree Approximation) ---\n",
    "    steiner_nodes = set()\n",
    "    steiner_edges = set()\n",
    "    for u, v in mst.edges():\n",
    "        try:\n",
    "            sp = nx.shortest_path(G_undirected, source=u, target=v)\n",
    "            steiner_nodes.update(sp)\n",
    "            for i in range(len(sp)-1):\n",
    "                steiner_edges.add((sp[i], sp[i+1]))\n",
    "        except nx.NetworkXNoPath:\n",
    "            continue\n",
    "\n",
    "    # --- Build visualization graph (H_full) ---\n",
    "    H_full = G.copy()\n",
    "    for n, data in H_full.nodes(data=True):\n",
    "        data[\"color\"] = \"lightgray\"\n",
    "        data[\"borderWidth\"] = 1\n",
    "    for u, v, edata in H_full.edges(data=True):\n",
    "        edata[\"color\"] = \"lightgray\"\n",
    "        edata[\"width\"] = 1\n",
    "\n",
    "    # Color nodes:\n",
    "    # Activated nodes are green.\n",
    "    # Steiner nodes (not activated) are yellow.\n",
    "    for n in H_full.nodes:\n",
    "        if n in activated:\n",
    "            H_full.nodes[n][\"color\"] = \"green\"\n",
    "            H_full.nodes[n][\"borderWidth\"] = 3\n",
    "        elif n in steiner_nodes:\n",
    "            H_full.nodes[n][\"color\"] = \"yellow\"\n",
    "            H_full.nodes[n][\"borderWidth\"] = 3\n",
    "\n",
    "    # Color edges that are part of the Steiner tree union in green.\n",
    "    for (u, v) in steiner_edges:\n",
    "        if H_full.has_edge(u, v):\n",
    "            H_full[u][v][\"color\"] = \"green\"\n",
    "            H_full[u][v][\"width\"] = 3\n",
    "        elif H_full.has_edge(v, u):\n",
    "            H_full[v][u][\"color\"] = \"green\"\n",
    "            H_full[v][u][\"width\"] = 3\n",
    "\n",
    "    # Additional: Mark red edges for any direct connection between nodes in (activated U steiner_nodes)\n",
    "    union_nodes = activated.union(steiner_nodes)\n",
    "    for u, v, edata in H_full.edges(data=True):\n",
    "        if u in union_nodes and v in union_nodes:\n",
    "            if edata.get(\"color\") != \"green\":\n",
    "                edata[\"color\"] = \"red\"\n",
    "                edata[\"width\"] = 2\n",
    "\n",
    "    # Filter to keep only the interconnected subgraph among union_nodes.\n",
    "    H_union = H_full.subgraph(union_nodes).copy()\n",
    "    if len(H_union.nodes()) > 0:\n",
    "        comps = list(nx.connected_components(H_union.to_undirected()))\n",
    "        if comps:\n",
    "            largest_comp = max(comps, key=len)\n",
    "            H_union = H_union.subgraph(largest_comp).copy()\n",
    "    # Remove nodes with degree < 2 to avoid isolated parts.\n",
    "    nodes_to_remove = [n for n in H_union.nodes() if H_union.degree(n) < 2]\n",
    "    H_union.remove_nodes_from(nodes_to_remove)\n",
    "\n",
    "    # Merge H_union back into H_full (grey out nodes not in H_union).\n",
    "    for n in H_full.nodes:\n",
    "        if n not in H_union.nodes():\n",
    "            H_full.nodes[n][\"color\"] = \"lightgray\"\n",
    "            H_full.nodes[n][\"borderWidth\"] = 1\n",
    "\n",
    "    # --- Build matching mappings from matching_nodes_edges.json for current query ---\n",
    "    node_chunk_mapping, edge_chunk_mapping = {}, {}\n",
    "    if query in matching_nodes_edges:\n",
    "        qdata = matching_nodes_edges[query]\n",
    "        if \"nodes\" in qdata:\n",
    "            for rec in qdata[\"nodes\"]:\n",
    "                nid = rec.get(\"kg_node_id\") or rec.get(\"node_id\")\n",
    "                if nid:\n",
    "                    node_chunk_mapping[nid] = rec.get(\"chunk_ids\", [])\n",
    "        if \"edges\" in qdata:\n",
    "            for rec in qdata[\"edges\"]:\n",
    "                eid = rec.get(\"kg_edge_id\") or rec.get(\"edge_id\")\n",
    "                # Alternatively, you could use a tuple key if available.\n",
    "                if eid:\n",
    "                    edge_chunk_mapping[eid] = rec.get(\"chunk_ids\", [])\n",
    "    # --- Sequence Extraction via DFS Traversal ---\n",
    "    # Choose starting node: from query_matches with highest similarity.\n",
    "    starting_node = None\n",
    "    best_sim = -1\n",
    "    if query in query_matches and \"nodes\" in query_matches[query]:\n",
    "        for rec in query_matches[query][\"nodes\"]:\n",
    "            sim = rec.get(\"similarity\", 0)\n",
    "            if sim > best_sim:\n",
    "                best_sim = sim\n",
    "                starting_node = rec.get(\"kg_node_id\") or rec.get(\"node_id\")\n",
    "    if starting_node is None or starting_node not in H_union.nodes():\n",
    "        if len(H_union.nodes()) > 0:\n",
    "            starting_node = list(H_union.nodes())[0]\n",
    "        else:\n",
    "            print(f\"No interconnected subgraph available for query: {query}\")\n",
    "            continue\n",
    "\n",
    "    # Perform DFS traversal on H_union (treat as undirected) to get ordered sequence.\n",
    "    dfs_nodes = list(nx.dfs_preorder_nodes(H_union.to_undirected(), source=starting_node))\n",
    "    \n",
    "    sequence = []\n",
    "    for idx, node in enumerate(dfs_nodes):\n",
    "        data = H_union.nodes[node]\n",
    "        # Try to extract text and chunk_ids from payload.\n",
    "        text = \"\"\n",
    "        chunk_ids = []\n",
    "        if \"payload\" in data and isinstance(data[\"payload\"], dict):\n",
    "            text = data[\"payload\"].get(\"text\", \"\")\n",
    "            chunk_ids = data[\"payload\"].get(\"chunk_ids\", [])\n",
    "        if not text:\n",
    "            text = data.get(\"label\", node)\n",
    "        # If no chunk_ids in payload, fill from matching mapping.\n",
    "        if not chunk_ids and node in node_chunk_mapping:\n",
    "            chunk_ids = node_chunk_mapping[node]\n",
    "        sequence.append({\n",
    "            \"type\": \"node\",\n",
    "            \"id\": node,\n",
    "            \"text\": text,\n",
    "            \"color\": data.get(\"color\"),\n",
    "            \"chunk_ids\": chunk_ids\n",
    "        })\n",
    "        # If not the last node, add edge info.\n",
    "        if idx < len(dfs_nodes) - 1:\n",
    "            next_node = dfs_nodes[idx+1]\n",
    "            edge_data = None\n",
    "            if H_union.has_edge(node, next_node):\n",
    "                edge_data = H_union.get_edge_data(node, next_node)\n",
    "            elif H_union.has_edge(next_node, node):\n",
    "                edge_data = H_union.get_edge_data(next_node, node)\n",
    "            edge_text = \"\"\n",
    "            edge_chunk_ids = []\n",
    "            if edge_data:\n",
    "                edge_text = edge_data.get(\"label\", \"\")\n",
    "                # If edge does not include chunk_ids, try to get from mapping using an edge key.\n",
    "                # Here we form a key as \"node--next_node\".\n",
    "                edge_key = f\"{node}--{next_node}\"\n",
    "                if \"chunk_ids\" in edge_data and edge_data[\"chunk_ids\"]:\n",
    "                    edge_chunk_ids = edge_data[\"chunk_ids\"]\n",
    "                elif edge_key in edge_chunk_mapping:\n",
    "                    edge_chunk_ids = edge_chunk_mapping[edge_key]\n",
    "            sequence.append({\n",
    "                \"type\": \"edge\",\n",
    "                \"from\": node,\n",
    "                \"to\": next_node,\n",
    "                \"text\": edge_text,\n",
    "                \"color\": edge_data.get(\"color\") if edge_data else \"\",\n",
    "                \"chunk_ids\": edge_chunk_ids\n",
    "            })\n",
    "\n",
    "    # Save the retrieved sequence to a JSON file.\n",
    "    safe_query = re.sub(r'[^\\w\\s-]', '', query).strip().replace(\" \", \"_\")\n",
    "    sequence_output_path = os.path.join(sequence_output_dir, f\"{safe_query}_sequence.json\")\n",
    "    with open(sequence_output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(sequence, f, indent=2)\n",
    "    print(f\"Retrieved sequence for query:\\n  {query}\\nSaved to: {os.path.realpath(sequence_output_path)}\")\n",
    "    \n",
    "    # --- Generate Visualization with PyVis (as before) ---\n",
    "    net = Network(height=\"750px\", width=\"100%\", directed=True, cdn_resources=\"remote\", notebook=False)\n",
    "    net.from_nx(H_full)\n",
    "    for node in net.nodes:\n",
    "        node[\"title\"] = node.get(\"label\", node.get(\"id\", \"\"))\n",
    "        node[\"label\"] = node.get(\"label\", node.get(\"id\", \"\"))\n",
    "    for edge in net.edges:\n",
    "        edge[\"title\"] = edge.get(\"label\", \"\")\n",
    "        edge[\"label\"] = edge.get(\"label\", \"\")\n",
    "    vis_output_path = os.path.join(output_dir, f\"{safe_query}_stcover.html\")\n",
    "    html_str = net.generate_html(notebook=False)\n",
    "    with open(vis_output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(html_str)\n",
    "    webbrowser.open(\"file://\" + os.path.realpath(vis_output_path))\n",
    "    viz2_path = os.path.realpath(vis_output_path)\n",
    "    print(f\"Covering (flood fill) visualization for query:\\n  {query}\\nSaved to: {os.path.realpath(vis_output_path)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aca89188-5f29-4d30-b9c9-aa74e0a28d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved sequence for query:\n",
      "  Summarize Cheerayu Chowhan's work experience at Impact Guru based on the extracted roles, dates, responsibilities, and accomplishments.\n",
      "Saved to: C:\\Users\\cheer\\rv_v1.3\\SOT\\SoT\\retrieved_sequences\\Summarize_Cheerayu_Chowhans_work_experience_at_Impact_Guru_based_on_the_extracted_roles_dates_responsibilities_and_accomplishments_sequence.json\n",
      "Covering (flood fill) visualization for query:\n",
      "  Summarize Cheerayu Chowhan's work experience at Impact Guru based on the extracted roles, dates, responsibilities, and accomplishments.\n",
      "Saved to: C:\\Users\\cheer\\rv_v1.3\\SOT\\SoT\\query_dfs_visualizations\\Summarize_Cheerayu_Chowhans_work_experience_at_Impact_Guru_based_on_the_extracted_roles_dates_responsibilities_and_accomplishments_stcover.html\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import networkx as nx\n",
    "from pyvis.network import Network\n",
    "import webbrowser\n",
    "import re\n",
    "\n",
    "# --- File Paths ---\n",
    "graphml_file = \"kg_entities_relations.graphml\"      # Full KG graph (GraphML)\n",
    "query_matches_file = \"query_matches.json\"             # Contains activated nodes (with similarity) per query\n",
    "matching_nodes_edges_file = \"matching_nodes_edges.json\"  # File with nodes/edges and their chunk_ids\n",
    "output_dir = \"query_dfs_visualizations\"               # Directory to save connectivity visualizations\n",
    "sequence_output_dir = \"retrieved_sequences\"           # Directory to save the ordered retrieved knowledge JSONs\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "os.makedirs(sequence_output_dir, exist_ok=True)\n",
    "\n",
    "def load_json(filepath):\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def get_activated_nodes(query, query_matches):\n",
    "    \"\"\"\n",
    "    Returns a set of activated node IDs (using 'kg_node_id' or 'node_id')\n",
    "    and also returns the record with the highest similarity among activated nodes.\n",
    "    \"\"\"\n",
    "    activated = set()\n",
    "    best_record = None\n",
    "    best_sim = -1\n",
    "    if query in query_matches and \"nodes\" in query_matches[query]:\n",
    "        for rec in query_matches[query][\"nodes\"]:\n",
    "            node_id = rec.get(\"kg_node_id\") or rec.get(\"node_id\")\n",
    "            if node_id:\n",
    "                activated.add(node_id)\n",
    "                sim = rec.get(\"similarity\", 0)\n",
    "                if sim > best_sim:\n",
    "                    best_sim = sim\n",
    "                    best_record = rec\n",
    "    return activated, best_record\n",
    "\n",
    "# --- Load the full KG graph (directed) and also create an undirected version ---\n",
    "G_directed = nx.read_graphml(graphml_file)\n",
    "G = G_directed  # We'll use the directed graph for visualization later.\n",
    "G_undirected = G.to_undirected()\n",
    "\n",
    "# --- Load query matches ---\n",
    "query_matches = load_json(query_matches_file)\n",
    "# --- Load matching nodes/edges to get chunk references if needed ---\n",
    "matching_nodes_edges = load_json(matching_nodes_edges_file)\n",
    "\n",
    "# For current query, build mapping for nodes and edges from matching file.\n",
    "def build_matching_mappings(query, matching_data):\n",
    "    node_map = {}\n",
    "    edge_map = {}\n",
    "    if query in matching_data:\n",
    "        qdata = matching_data[query]\n",
    "        if \"nodes\" in qdata:\n",
    "            for rec in qdata[\"nodes\"]:\n",
    "                nid = rec.get(\"kg_node_id\") or rec.get(\"node_id\")\n",
    "                if nid:\n",
    "                    node_map[nid] = rec.get(\"chunk_ids\", [])\n",
    "        if \"edges\" in qdata:\n",
    "            for rec in qdata[\"edges\"]:\n",
    "                eid = rec.get(\"kg_edge_id\") or rec.get(\"edge_id\")\n",
    "                # Alternatively, you may define a key as \"from--to\" if no id exists.\n",
    "                if eid:\n",
    "                    edge_map[eid] = rec.get(\"chunk_ids\", [])\n",
    "    return node_map, edge_map\n",
    "\n",
    "# --- Compute the interconnected subgraph as before (Steiner Tree approximation) ---\n",
    "for query in query_matches.keys():\n",
    "    activated, best_rec = get_activated_nodes(query, query_matches)\n",
    "    if not activated:\n",
    "        print(f\"No activated nodes for query: {query}\")\n",
    "        continue\n",
    "\n",
    "    # Find the connected component in G_undirected that contains the majority of activated nodes.\n",
    "    comp_dict = {}\n",
    "    for comp in nx.connected_components(G_undirected):\n",
    "        inter = activated & comp\n",
    "        if inter:\n",
    "            comp_dict[frozenset(comp)] = inter\n",
    "    if not comp_dict:\n",
    "        print(f\"No connected component found for activated nodes in query: {query}\")\n",
    "        continue\n",
    "    best_comp = max(comp_dict.items(), key=lambda x: len(x[1]))[0]\n",
    "    activated_in_comp = activated & best_comp\n",
    "\n",
    "    # --- Compute metric closure among activated nodes in best_comp ---\n",
    "    metric_closure = nx.Graph()\n",
    "    activated_list = list(activated_in_comp)\n",
    "    for i in range(len(activated_list)):\n",
    "        for j in range(i+1, len(activated_list)):\n",
    "            u = activated_list[i]\n",
    "            v = activated_list[j]\n",
    "            try:\n",
    "                dist = nx.shortest_path_length(G_undirected, source=u, target=v)\n",
    "                metric_closure.add_edge(u, v, weight=dist)\n",
    "            except nx.NetworkXNoPath:\n",
    "                continue\n",
    "    if metric_closure.number_of_edges() == 0:\n",
    "        print(f\"No connecting paths among activated nodes for query: {query}\")\n",
    "        continue\n",
    "\n",
    "    # --- Compute MST on metric closure ---\n",
    "    mst = nx.minimum_spanning_tree(metric_closure, weight='weight')\n",
    "\n",
    "    # --- Expand MST edges to actual paths in G_undirected (Steiner Tree Approximation) ---\n",
    "    steiner_nodes = set()\n",
    "    steiner_edges = set()\n",
    "    for u, v in mst.edges():\n",
    "        try:\n",
    "            sp = nx.shortest_path(G_undirected, source=u, target=v)\n",
    "            steiner_nodes.update(sp)\n",
    "            for i in range(len(sp)-1):\n",
    "                steiner_edges.add((sp[i], sp[i+1]))\n",
    "        except nx.NetworkXNoPath:\n",
    "            continue\n",
    "\n",
    "    # --- Build visualization graph (H_full) ---\n",
    "    H_full = G.copy()\n",
    "    for n, data in H_full.nodes(data=True):\n",
    "        data[\"color\"] = \"lightgray\"\n",
    "        data[\"borderWidth\"] = 1\n",
    "    for u, v, edata in H_full.edges(data=True):\n",
    "        edata[\"color\"] = \"lightgray\"\n",
    "        edata[\"width\"] = 1\n",
    "\n",
    "    # Color nodes:\n",
    "    # Activated nodes are green.\n",
    "    # Steiner nodes (not activated) are yellow.\n",
    "    for n in H_full.nodes:\n",
    "        if n in activated:\n",
    "            H_full.nodes[n][\"color\"] = \"green\"\n",
    "            H_full.nodes[n][\"borderWidth\"] = 3\n",
    "        elif n in steiner_nodes:\n",
    "            H_full.nodes[n][\"color\"] = \"yellow\"\n",
    "            H_full.nodes[n][\"borderWidth\"] = 3\n",
    "\n",
    "    # Color edges that are part of the Steiner tree union in green.\n",
    "    for (u, v) in steiner_edges:\n",
    "        if H_full.has_edge(u, v):\n",
    "            H_full[u][v][\"color\"] = \"green\"\n",
    "            H_full[u][v][\"width\"] = 3\n",
    "        elif H_full.has_edge(v, u):\n",
    "            H_full[v][u][\"color\"] = \"green\"\n",
    "            H_full[v][u][\"width\"] = 3\n",
    "\n",
    "    # Additional: Mark red edges for any direct connection between nodes in (activated U steiner_nodes)\n",
    "    union_nodes = activated.union(steiner_nodes)\n",
    "    for u, v, edata in H_full.edges(data=True):\n",
    "        if u in union_nodes and v in union_nodes:\n",
    "            if edata.get(\"color\") != \"green\":\n",
    "                edata[\"color\"] = \"red\"\n",
    "                edata[\"width\"] = 2\n",
    "\n",
    "    # Filter to keep only the interconnected subgraph among union_nodes.\n",
    "    H_union = H_full.subgraph(union_nodes).copy()\n",
    "    if len(H_union.nodes()) > 0:\n",
    "        comps = list(nx.connected_components(H_union.to_undirected()))\n",
    "        if comps:\n",
    "            largest_comp = max(comps, key=len)\n",
    "            H_union = H_union.subgraph(largest_comp).copy()\n",
    "    # Remove nodes with degree < 2 to avoid isolated parts.\n",
    "    nodes_to_remove = [n for n in H_union.nodes() if H_union.degree(n) < 2]\n",
    "    H_union.remove_nodes_from(nodes_to_remove)\n",
    "\n",
    "    # Merge H_union back into H_full (grey out nodes not in H_union).\n",
    "    for n in H_full.nodes:\n",
    "        if n not in H_union.nodes():\n",
    "            H_full.nodes[n][\"color\"] = \"lightgray\"\n",
    "            H_full.nodes[n][\"borderWidth\"] = 1\n",
    "\n",
    "    # --- Build matching mappings from matching_nodes_edges.json for current query ---\n",
    "    node_chunk_mapping, edge_chunk_mapping = {}, {}\n",
    "    if query in matching_nodes_edges:\n",
    "        qdata = matching_nodes_edges[query]\n",
    "        if \"nodes\" in qdata:\n",
    "            for rec in qdata[\"nodes\"]:\n",
    "                nid = rec.get(\"kg_node_id\") or rec.get(\"node_id\")\n",
    "                if nid:\n",
    "                    node_chunk_mapping[nid] = rec.get(\"chunk_ids\", [])\n",
    "        if \"edges\" in qdata:\n",
    "            for rec in qdata[\"edges\"]:\n",
    "                eid = rec.get(\"kg_edge_id\") or rec.get(\"edge_id\")\n",
    "                if eid:\n",
    "                    edge_chunk_mapping[eid] = rec.get(\"chunk_ids\", [])\n",
    "    # --- Sequence Extraction via DFS Traversal ---\n",
    "    # Choose starting node: from query_matches with highest similarity.\n",
    "    starting_node = None\n",
    "    best_sim = -1\n",
    "    if query in query_matches and \"nodes\" in query_matches[query]:\n",
    "        for rec in query_matches[query][\"nodes\"]:\n",
    "            sim = rec.get(\"similarity\", 0)\n",
    "            if sim > best_sim:\n",
    "                best_sim = sim\n",
    "                starting_node = rec.get(\"kg_node_id\") or rec.get(\"node_id\")\n",
    "    if starting_node is None or starting_node not in H_union.nodes():\n",
    "        if len(H_union.nodes()) > 0:\n",
    "            starting_node = list(H_union.nodes())[0]\n",
    "        else:\n",
    "            print(f\"No interconnected subgraph available for query: {query}\")\n",
    "            continue\n",
    "\n",
    "    # Perform DFS traversal on H_union (treat as undirected) to get ordered sequence.\n",
    "    dfs_nodes = list(nx.dfs_preorder_nodes(H_union.to_undirected(), source=starting_node))\n",
    "    \n",
    "    sequence = []\n",
    "    for idx, node in enumerate(dfs_nodes):\n",
    "        data = H_union.nodes[node]\n",
    "        # Try to extract text and chunk_ids from payload.\n",
    "        text = \"\"\n",
    "        chunk_ids = []\n",
    "        if \"payload\" in data and isinstance(data[\"payload\"], dict):\n",
    "            text = data[\"payload\"].get(\"text\", \"\")\n",
    "            chunk_ids = data[\"payload\"].get(\"chunk_ids\", [])\n",
    "        if not text:\n",
    "            text = data.get(\"label\", node)\n",
    "        if not chunk_ids and node in node_chunk_mapping:\n",
    "            chunk_ids = node_chunk_mapping[node]\n",
    "        sequence.append({\n",
    "            \"type\": \"node\",\n",
    "            \"id\": node,\n",
    "            \"text\": text,\n",
    "            \"color\": data.get(\"color\"),\n",
    "            \"chunk_ids\": chunk_ids\n",
    "        })\n",
    "        if idx < len(dfs_nodes) - 1:\n",
    "            next_node = dfs_nodes[idx+1]\n",
    "            edge_data = None\n",
    "            if H_union.has_edge(node, next_node):\n",
    "                edge_data = H_union.get_edge_data(node, next_node)\n",
    "            elif H_union.has_edge(next_node, node):\n",
    "                edge_data = H_union.get_edge_data(next_node, node)\n",
    "            edge_text = \"\"\n",
    "            edge_chunk_ids = []\n",
    "            if edge_data:\n",
    "                edge_text = edge_data.get(\"label\", \"\")\n",
    "                edge_key = f\"{node}--{next_node}\"\n",
    "                if \"chunk_ids\" in edge_data and edge_data[\"chunk_ids\"]:\n",
    "                    edge_chunk_ids = edge_data[\"chunk_ids\"]\n",
    "                elif edge_key in edge_chunk_mapping:\n",
    "                    edge_chunk_ids = edge_chunk_mapping[edge_key]\n",
    "            sequence.append({\n",
    "                \"type\": \"edge\",\n",
    "                \"from\": node,\n",
    "                \"to\": next_node,\n",
    "                \"text\": edge_text,\n",
    "                \"color\": edge_data.get(\"color\") if edge_data else \"\",\n",
    "                \"chunk_ids\": edge_chunk_ids\n",
    "            })\n",
    "\n",
    "    # Save the retrieved sequence to a JSON file.\n",
    "    safe_query = re.sub(r'[^\\w\\s-]', '', query).strip().replace(\" \", \"_\")\n",
    "    sequence_output_path = os.path.join(sequence_output_dir, f\"{safe_query}_sequence.json\")\n",
    "    with open(sequence_output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(sequence, f, indent=2)\n",
    "    print(f\"Retrieved sequence for query:\\n  {query}\\nSaved to: {os.path.realpath(sequence_output_path)}\")\n",
    "    \n",
    "    # --- Generate Visualization with PyVis (as before) ---\n",
    "    net = Network(height=\"750px\", width=\"100%\", directed=True, cdn_resources=\"remote\", notebook=False, bgcolor=\"#000000\")\n",
    "    net.from_nx(H_full)\n",
    "    \n",
    "    # Adjust node appearance:\n",
    "    for node in net.nodes:\n",
    "        # Save the original label (or use node id) for tooltips.\n",
    "        original_label = node.get(\"label\", node.get(\"id\"))\n",
    "        if node[\"id\"] in activated:\n",
    "            # For activated (green) nodes, show static, larger annotation.\n",
    "            node[\"title\"] = original_label\n",
    "            node[\"label\"] = original_label\n",
    "        else:\n",
    "            # For non-highlighter nodes (lightgray or yellow), remove static annotation.\n",
    "            node[\"title\"] = original_label  # tooltip remains on hover\n",
    "            node[\"label\"] = \"\"\n",
    "    \n",
    "    # Adjust edge appearance:\n",
    "    for edge in net.edges:\n",
    "        original_label = edge.get(\"label\", \"\")\n",
    "        # If the edge is highlighted (green or red), keep its static annotation.\n",
    "        if edge.get(\"color\") in [\"green\", \"red\"]:\n",
    "            edge[\"title\"] = original_label\n",
    "            edge[\"label\"] = original_label\n",
    "        else:\n",
    "            # For non-highlighted edges, remove static annotation.\n",
    "            edge[\"title\"] = original_label  # tooltip remains on hover\n",
    "            edge[\"label\"] = \"\"\n",
    "    \n",
    "    vis_output_path = os.path.join(output_dir, f\"{safe_query}_stcover.html\")\n",
    "    html_str = net.generate_html(notebook=False)\n",
    "    with open(vis_output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(html_str)\n",
    "    webbrowser.open(\"file://\" + os.path.realpath(vis_output_path))\n",
    "    viz2_path = os.path.realpath(vis_output_path)\n",
    "    print(f\"Covering (flood fill) visualization for query:\\n  {query}\\nSaved to: {viz2_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e96135-3dff-4d2c-bdca-7669e21c6941",
   "metadata": {},
   "source": [
    "# Collecting the querry , and retieved paths alogn with respective chunks to provide a comprehensive answer "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1b5e02-0357-4858-8d54-52100993d9cb",
   "metadata": {},
   "source": [
    "### Preparing the prompts \n",
    "\n",
    "\n",
    "### you need to include chunk_db.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "09599087-b100-4d73-a5fb-0bda8154182f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG prompt for query:\n",
      "  Summarize Cheerayu Chowhan's work experience at Impact Guru based on the extracted roles, dates, responsibilities, and accomplishments.\n",
      "Saved to: C:\\Users\\cheer\\rv_v1.3\\SOT\\SoT\\rag_prompts\\Summarize_Cheerayu_Chowhans_work_experience_at_Impact_Guru_based_on_the_extracted_roles_dates_responsibilities_and_accomplishments_prompt.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "\n",
    "# --- File Paths ---\n",
    "query_embeddings_file = \"query_embeddings.json\"   # Contains query decomposition (unique_nodes & unique_relations)\n",
    "sequence_dir = \"retrieved_sequences\"                # Directory where DFS sequence JSON files are stored (named as {safe_query}_sequence.json)\n",
    "chunk_db_file = \"chunk_db.json\"                     # Chunk database (contains payload.text for each chunk)\n",
    "rag_prompts_dir = \"rag_prompts\"                     # Output directory for final RAG prompts\n",
    "\n",
    "os.makedirs(rag_prompts_dir, exist_ok=True)\n",
    "\n",
    "def load_json(filepath):\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "# --- Load Query Embeddings (Query Decomposition) ---\n",
    "query_embeddings = load_json(query_embeddings_file)\n",
    "\n",
    "# --- Build Chunk Mapping: from chunk ID to its text ---\n",
    "chunk_db = load_json(chunk_db_file)\n",
    "chunk_mapping = {}\n",
    "if isinstance(chunk_db, dict) and \"data\" in chunk_db:\n",
    "    for rec in chunk_db[\"data\"]:\n",
    "        cid = rec.get(\"id\")\n",
    "        if cid and \"payload\" in rec and isinstance(rec[\"payload\"], dict):\n",
    "            text = rec[\"payload\"].get(\"text\", \"\").strip()\n",
    "            if text:\n",
    "                chunk_mapping[cid] = text\n",
    "\n",
    "# --- Process each query from query_embeddings ---\n",
    "for query, qdata in query_embeddings.items():\n",
    "    # Derive a safe filename base from the query.\n",
    "    safe_query = re.sub(r'[^\\w\\s-]', '', query).strip().replace(\" \", \"_\")\n",
    "    \n",
    "    # Load the corresponding DFS sequence from retrieved_sequences.\n",
    "    seq_filename = f\"{safe_query}_sequence.json\"\n",
    "    seq_filepath = os.path.join(sequence_dir, seq_filename)\n",
    "    if os.path.exists(seq_filepath):\n",
    "        sequence_data = load_json(seq_filepath)\n",
    "    else:\n",
    "        print(f\"Sequence file not found for query: {query}\")\n",
    "        continue\n",
    "\n",
    "    # Collect all unique chunk IDs from the sequence (but we will only display the text later).\n",
    "    unique_chunk_ids = set()\n",
    "    for step in sequence_data:\n",
    "        for cid in step.get(\"chunk_ids\", []):\n",
    "            unique_chunk_ids.add(cid)\n",
    "    \n",
    "    # Build unique chunk texts (deduplicated) using chunk_mapping.\n",
    "    unique_chunk_texts = []\n",
    "    for cid in unique_chunk_ids:\n",
    "        if cid in chunk_mapping:\n",
    "            unique_chunk_texts.append(chunk_mapping[cid])\n",
    "    \n",
    "    # --- Build the detailed prompt ---\n",
    "    prompt = f\"\"\"[SYSTEM PROMPT]\n",
    "You are a component of a Retrieval-Augmented Generation (RAG) system designed to analyze LinkedIn profiles to answer user queries. The system processes each query by:\n",
    "  1. Decomposing the query into key nodes (entities) and relations (extracted from LinkedIn profile data).\n",
    "  2. Retrieving an ordered information sequence by traversing a knowledge graph.\n",
    "  3. Fetching the original chunk texts corresponding to the information retrieved.\n",
    "Your task is to follow the instructions to answer the query from the [RETRIEVED SEQUENCE]  & [UNIQUE CHUNK TEXTS].\n",
    "The Provided context with [RETRIEVED SEQUENCE] & [UNIQUE CHUNK TEXTS] are always complete in nature and answer must be provided using the same context.\n",
    "Below is the complete context provided for the query.\n",
    "--------------------------------------------------\n",
    "[QUERY]\n",
    "{query}\n",
    "--------------------------------------------------\n",
    "[QUERY DECOMPOSITION]\n",
    "Unique Nodes: {qdata.get(\"unique_nodes\", [])}\n",
    "Unique Relations: {qdata.get(\"unique_relations\", [])}\n",
    "--------------------------------------------------\n",
    "[INSTRUCTIONS]\n",
    "Using the context below and chunk texts provided, first provide your reasoning (between [START_THINKING] and [END_THINKING]) to solve the query, then generate a final detailed answer strictly between [START_ANSWER] and [END_ANSWER]. You must base your answer solely on the context provided with sequenses and chunk text without assuming any additional information.\n",
    "--------------------------------------------------\n",
    "[RETRIEVED SEQUENCE]\n",
    "Below is the ordered sequence of nodes and edges with their text and color:\n",
    "\"\"\"\n",
    "    # Append the sequence steps (without printing chunk IDs).\n",
    "    for step in sequence_data:\n",
    "        if step[\"type\"] == \"node\":\n",
    "            prompt += f\"\\nNODE: ID: {step['id']} | Text: {step['text']} | Color: {step['color']}\"\n",
    "        elif step[\"type\"] == \"edge\":\n",
    "            prompt += f\"\\nEDGE: From: {step['from']} To: {step['to']} | Text: {step['text']} | Color: {step['color']}\"\n",
    "    prompt += \"\\n--------------------------------------------------\\n\"\n",
    "    prompt += \"[UNIQUE CHUNK TEXTS]\\n\"\n",
    "    for text in unique_chunk_texts:\n",
    "        prompt += f\"\\n{text}\"\n",
    "    prompt += \"\\n--------------------------------------------------\\n\"\n",
    "    prompt += \"\"\"[START_THINKING]\n",
    "(Your reasoning goes here...)\n",
    "[END_THINKING]\n",
    "\n",
    "[START_ANSWER]\n",
    "(Your final answer goes here...)\n",
    "[END_ANSWER]\"\"\"\n",
    "\n",
    "    # Save the prompt to a file.\n",
    "    prompt_filepath = os.path.join(rag_prompts_dir, f\"{safe_query}_prompt.txt\")\n",
    "    with open(prompt_filepath, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(prompt)\n",
    "    print(f\"RAG prompt for query:\\n  {query}\\nSaved to: {os.path.realpath(prompt_filepath)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4be24d9a-21d3-4c29-bbe4-1d11f0b44eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response for query: Summarize Cheerayu Chowhans work experience at Impact Guru based on the extracted roles dates responsibilities and accomplishments\n",
      "[START_THINKING]\n",
      "The query asks for a summary of Cheerayu Chowhan's work experience at ImpactGuru.  The provided knowledge graph contains information about Cheerayu Chowhan's roles, dates, responsibilities, and accomplishments at ImpactGuru.  I need to extract this information from the relevant edges and nodes in the graph and the corresponding chunk texts.\n",
      "[END_THINKING]\n",
      "\n",
      "[START_ANSWER]\n",
      "Based on the provided data, Cheerayu Chowhan worked at ImpactGuru as a Strategic Partnership Alliance Intern.  During this internship, they conducted research, developed growth strategies, and facilitated insights apps for hospital partnership pitches.  They leveraged web scraping and Selenium automation to reduce manual effort by 50.72%, developed a LinkedIn Profile Analysis Tool that reduced sales research time by 32.14%, provided daily competitor campaign updates boosting market intelligence by 27.86%, and applied regular expressions and XML concepts resulting in a time reduction of approximately 43.29%.\n",
      "[END_ANSWER]\n",
      "\n",
      "----------------------------------------\n",
      "All Gemini LLM responses saved to: C:\\Users\\cheer\\rv_v1.3\\SOT\\SoT\\gemini_responses.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "# --- File Paths ---\n",
    "rag_prompts_dir = \"rag_prompts\"     # Directory containing prompt text files\n",
    "output_responses_file = \"gemini_responses.json\"  # File to save responses\n",
    "\n",
    "# --- Gemini LLM Configuration ---\n",
    "API_KEY = \"AIzaSyCjbGRnG3XdvIeUTKnwZ1HgS0sSYGg-t5E\"  # Replace with your actual API key\n",
    "MODEL = \"gemini-1.5-flash\"  # Using Gemini 1.5 Flash\n",
    "\n",
    "client = genai.Client(api_key=API_KEY)\n",
    "\n",
    "# --- Updated system instruction ---\n",
    "system_instruction = (\n",
    "    \"You are a component of a Retrieval-Augmented Generation (RAG) system designed to analyze LinkedIn profiles to answer user queries. \"\n",
    "    \"The system processes each query by:\\n\"\n",
    "    \"  1. Decomposing the query into key nodes (entities) and relations (extracted from LinkedIn profile data).\\n\"\n",
    "    \"  2. Retrieving an ordered information sequence by traversing a knowledge graph.\\n\"\n",
    "    \"  3. Fetching the original chunk texts corresponding to the information retrieved.\\n\"\n",
    "    \"Your task is to follow the instructions to answer the query from the [RETRIEVED SEQUENCE] & [UNIQUE CHUNK TEXTS]. \"\n",
    "    \"The provided context with [RETRIEVED SEQUENCE] & [UNIQUE CHUNK TEXTS] is always complete in nature and the answer must be provided using the same context.\\n\"\n",
    "    \"Below is the complete context provided for the query.\"\n",
    ")\n",
    "\n",
    "# Configuration for the generation with the system instruction.\n",
    "config = types.GenerateContentConfig(\n",
    "    system_instruction=system_instruction,\n",
    "    max_output_tokens=8000,\n",
    "    temperature=0.1\n",
    ")\n",
    "\n",
    "# --- Load all prompt files and make LLM calls ---\n",
    "responses = {}  # Dictionary to hold query: response_text\n",
    "\n",
    "for filename in os.listdir(rag_prompts_dir):\n",
    "    # Expect filenames like {safe_query}_prompt.txt\n",
    "    if not filename.endswith(\"_prompt.txt\"):\n",
    "        continue\n",
    "    filepath = os.path.join(rag_prompts_dir, filename)\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        prompt_text = f.read()\n",
    "    \n",
    "    # Derive query text from filename (replace underscores with spaces, remove _prompt.txt)\n",
    "    safe_query = filename.replace(\"_prompt.txt\", \"\")\n",
    "    query_text = safe_query.replace(\"_\", \" \")\n",
    "    \n",
    "    # Call the Gemini LLM with the updated system prompt.\n",
    "    try:\n",
    "        response = client.models.generate_content(\n",
    "            model=MODEL,\n",
    "            contents=[prompt_text],\n",
    "            config=config\n",
    "        )\n",
    "        # Store the response.\n",
    "        responses[query_text] = response.text\n",
    "        viz_response = response.text\n",
    "        print(f\"Response for query: {query_text}\\n{response.text}\\n{'-'*40}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing query '{query_text}': {e}\")\n",
    "        responses[query_text] = f\"Error: {e}\"\n",
    "\n",
    "# --- Save all responses to a JSON file ---\n",
    "with open(output_responses_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(responses, f, indent=2)\n",
    "\n",
    "print(f\"All Gemini LLM responses saved to: {os.path.realpath(output_responses_file)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "91296bd1-cc9d-4302-aed0-d5aa1f175ce7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[START_THINKING]\\nThe query asks for a summary of Cheerayu Chowhan's work experience at ImpactGuru.  The provided knowledge graph contains information about Cheerayu Chowhan's roles, dates, responsibilities, and accomplishments at ImpactGuru.  I need to extract this information from the relevant edges and nodes in the graph and the corresponding chunk texts.\\n[END_THINKING]\\n\\n[START_ANSWER]\\nBased on the provided data, Cheerayu Chowhan worked at ImpactGuru as a Strategic Partnership Alliance Intern.  During this internship, they conducted research, developed growth strategies, and facilitated insights apps for hospital partnership pitches.  They leveraged web scraping and Selenium automation to reduce manual effort by 50.72%, developed a LinkedIn Profile Analysis Tool that reduced sales research time by 32.14%, provided daily competitor campaign updates boosting market intelligence by 27.86%, and applied regular expressions and XML concepts resulting in a time reduction of approximately 43.29%.\\n[END_ANSWER]\\n\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viz_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d798ec-ca86-44ef-8747-ab8b2b4b8c3f",
   "metadata": {},
   "source": [
    "# Transparent Workflow output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d00bdf66-cb88-4ef7-b499-3b768c2dc28c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined HTML file (workflow.html) generated successfully!\n"
     ]
    }
   ],
   "source": [
    "# Define your variables\n",
    "# question\n",
    "#paradigm \n",
    "enhanced_queires = combined_list \n",
    "image_file = image_path      # The image to display\n",
    "\n",
    "\n",
    "# Create an HTML page that includes:\n",
    "# - A box for the question text\n",
    "# - A box for the paradigm text\n",
    "# - A box for the enhanced queries list\n",
    "# - A box for the image visualization\n",
    "# - The two visualization boxes stacked vertically, with arrows between all boxes\n",
    "html_content = f\"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <title>KG Visualizations Dashboard</title>\n",
    "    <style>\n",
    "        body {{\n",
    "            font-family: Arial, sans-serif;\n",
    "            text-align: center;\n",
    "            margin: 0;\n",
    "            padding: 0;\n",
    "            background-color: #f7f7f7;\n",
    "        }}\n",
    "        .container {{\n",
    "            width: 90%;\n",
    "            margin: 20px auto;\n",
    "        }}\n",
    "        .box {{\n",
    "            background-color: #fff;\n",
    "            margin: 10px 0;\n",
    "            padding: 15px;\n",
    "            border: 2px solid #ccc;\n",
    "            box-shadow: 2px 2px 12px #aaa;\n",
    "        }}\n",
    "        iframe {{\n",
    "            width: 100%;\n",
    "            height: 600px; /* Adjust as needed */\n",
    "            border: none;\n",
    "        }}\n",
    "        .arrow {{\n",
    "            font-size: 48px;\n",
    "            color: #555;\n",
    "            margin: 20px 0;\n",
    "        }}\n",
    "        h2 {{\n",
    "            margin: 10px 0;\n",
    "        }}\n",
    "        .text-box {{\n",
    "            font-size: 20px;\n",
    "            font-weight: bold;\n",
    "        }}\n",
    "        ul {{\n",
    "            list-style: none;\n",
    "            padding: 0;\n",
    "        }}\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    <div class=\"container\">\n",
    "        <!-- Box for the Question -->\n",
    "        <div class=\"box text-box\">\n",
    "            <p>Question: {question}</p>\n",
    "        </div>\n",
    "        \n",
    "        <!-- Downward arrow -->\n",
    "        <div class=\"arrow\">&#8595;</div>\n",
    "        \n",
    "        <!-- Box for the Paradigm -->\n",
    "        <div class=\"box text-box\">\n",
    "            <p>Paradigm: {paradigm}</p>\n",
    "        </div>\n",
    "        \n",
    "        <!-- Downward arrow -->\n",
    "        <div class=\"arrow\">&#8595;</div>\n",
    "        \n",
    "        <!-- Box for Enhanced Queries -->\n",
    "        <div class=\"box text-box\">\n",
    "            <h2>Enhanced Queries</h2>\n",
    "            <ul>\n",
    "                {''.join(f\"<li>{eq}</li>\" for eq in enhanced_queires)}\n",
    "            </ul>\n",
    "        </div>\n",
    "        \n",
    "        <!-- Downward arrow -->\n",
    "        <div class=\"arrow\">&#8595;</div>\n",
    "        \n",
    "        <!-- Box for the Image Visualization -->\n",
    "        <div class=\"box\">\n",
    "            <h2>KG Visualization Image</h2>\n",
    "            <iframe src=\"{image_file}\"></iframe>\n",
    "        </div>\n",
    "        \n",
    "        <!-- Downward arrow -->\n",
    "        <div class=\"arrow\">&#8595;</div>\n",
    "        \n",
    "        <!-- First visualization box -->\n",
    "        <div class=\"box\">\n",
    "            <h2>Visualization 1</h2>\n",
    "            <iframe src=\"{viz1_path}\"></iframe>\n",
    "        </div>\n",
    "        \n",
    "        <!-- Downward arrow -->\n",
    "        <div class=\"arrow\">&#8595;</div>\n",
    "        \n",
    "        <!-- Second visualization box -->\n",
    "        <div class=\"box\">\n",
    "            <h2>Visualization 2</h2>\n",
    "            <iframe src=\"{viz2_path}\"></iframe>\n",
    "        </div>\n",
    "    </div>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "# Write the HTML content to a file\n",
    "with open(\"Workflow.html\", \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(html_content)\n",
    "\n",
    "print(\"Combined HTML file (workflow.html) generated successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f07d8253-232e-475c-8b5f-0f45fc66e0aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined HTML file (Workflow.html) generated successfully!\n"
     ]
    }
   ],
   "source": [
    "# Define your variables\n",
    "# question, paradigm, and viz_response should be defined earlier in your script\n",
    "# enhanced_queries is the combined list for enhanced queries\n",
    "enhanced_queires = combined_list \n",
    "image_file = image_path      # The image to display\n",
    "\n",
    "# Create an HTML page that includes:\n",
    "# - A box for the question text\n",
    "# - A box for the paradigm text\n",
    "# - A box for the enhanced queries list\n",
    "# - A box for the image visualization\n",
    "# - Two visualization boxes stacked vertically, with arrows between all boxes\n",
    "# - An additional iframe box after visualization 2 as the final response heading\n",
    "html_content = f\"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <title>KG Visualizations Dashboard</title>\n",
    "    <style>\n",
    "        body {{\n",
    "            font-family: Arial, sans-serif;\n",
    "            text-align: center;\n",
    "            margin: 0;\n",
    "            padding: 0;\n",
    "            background-color: #f7f7f7;\n",
    "        }}\n",
    "        .container {{\n",
    "            width: 90%;\n",
    "            margin: 20px auto;\n",
    "        }}\n",
    "        .box {{\n",
    "            background-color: #fff;\n",
    "            margin: 10px 0;\n",
    "            padding: 15px;\n",
    "            border: 2px solid #ccc;\n",
    "            box-shadow: 2px 2px 12px #aaa;\n",
    "        }}\n",
    "        iframe {{\n",
    "            width: 100%;\n",
    "            height: 600px; /* Adjust as needed */\n",
    "            border: none;\n",
    "        }}\n",
    "        .arrow {{\n",
    "            font-size: 48px;\n",
    "            color: #555;\n",
    "            margin: 20px 0;\n",
    "        }}\n",
    "        h2 {{\n",
    "            margin: 10px 0;\n",
    "        }}\n",
    "        .text-box {{\n",
    "            font-size: 20px;\n",
    "            font-weight: bold;\n",
    "        }}\n",
    "        ul {{\n",
    "            list-style: none;\n",
    "            padding: 0;\n",
    "        }}\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    <div class=\"container\">\n",
    "        <!-- Box for the Question -->\n",
    "        <div class=\"box text-box\">\n",
    "            <p>Question: {question}</p>\n",
    "        </div>\n",
    "        \n",
    "        <!-- Downward arrow -->\n",
    "        <div class=\"arrow\">&#8595;</div>\n",
    "        \n",
    "        <!-- Box for the Paradigm -->\n",
    "        <div class=\"box text-box\">\n",
    "            <p>Paradigm: {paradigm}</p>\n",
    "        </div>\n",
    "        \n",
    "        <!-- Downward arrow -->\n",
    "        <div class=\"arrow\">&#8595;</div>\n",
    "        \n",
    "        <!-- Box for Enhanced Queries -->\n",
    "        <div class=\"box text-box\">\n",
    "            <h2>Enhanced Queries</h2>\n",
    "            <ul>\n",
    "                {''.join(f\"<li>{eq}</li>\" for eq in enhanced_queires)}\n",
    "            </ul>\n",
    "        </div>\n",
    "        \n",
    "        <!-- Downward arrow -->\n",
    "        <div class=\"arrow\">&#8595;</div>\n",
    "        \n",
    "        <!-- Box for the Image Visualization -->\n",
    "        <div class=\"box\">\n",
    "            <h2>KG Visualization Image</h2>\n",
    "            <iframe src=\"{image_file}\"></iframe>\n",
    "        </div>\n",
    "        \n",
    "        <!-- Downward arrow -->\n",
    "        <div class=\"arrow\">&#8595;</div>\n",
    "        \n",
    "        <!-- First visualization box -->\n",
    "        <div class=\"box\">\n",
    "            <h2>Visualization 1</h2>\n",
    "            <iframe src=\"{viz1_path}\"></iframe>\n",
    "        </div>\n",
    "        \n",
    "        <!-- Downward arrow -->\n",
    "        <div class=\"arrow\">&#8595;</div>\n",
    "        \n",
    "        <!-- Second visualization box -->\n",
    "        <div class=\"box\">\n",
    "            <h2>Visualization 2</h2>\n",
    "            <iframe src=\"{viz2_path}\"></iframe>\n",
    "        </div>\n",
    "        \n",
    "        <!-- Downward arrow -->\n",
    "        <div class=\"arrow\">&#8595;</div>\n",
    "        \n",
    "        <!-- Final Response box -->\n",
    "        <div class=\"box text-box\">\n",
    "            <h2>Final Response: </h2>\n",
    "            <p>{viz_response}</p>\n",
    "        </div>\n",
    "       \n",
    "        \n",
    "    </div>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "# Write the HTML content to a file\n",
    "with open(\"Workflow.html\", \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(html_content)\n",
    "\n",
    "print(\"Combined HTML file (Workflow.html) generated successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6536f110-fc8b-4e7b-af56-30cfa1838092",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
